{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itskutush/Water-Quality-Analysis-of-South-Eastern-Costal-States-of-India/blob/main/water_quality_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vp4DTJnV5bbF",
        "outputId": "02ad47c6-a6e1-4063-e8dd-6a7550291a4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sklearn-features\n",
            "  Downloading sklearn_features-0.0.2-py3-none-any.whl (6.1 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from sklearn-features) (2.0.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sklearn-features) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sklearn-features) (1.11.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->sklearn-features) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->sklearn-features) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->sklearn-features) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->sklearn-features) (1.25.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sklearn-features) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sklearn-features) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->sklearn-features) (1.16.0)\n",
            "Installing collected packages: sklearn-features\n",
            "Successfully installed sklearn-features-0.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install sklearn-features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzIPZjmy6-os"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import scipy\n",
        "\n",
        "## Other\n",
        "import os, joblib, missingno\n",
        "\n",
        "## sklearn -- Preprocessing & Tuning & Transformation\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, PolynomialFeatures,OrdinalEncoder\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn_features.transformers import DataFrameSelector\n",
        "from sklearn.metrics import mean_squared_error\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpdWEsym3sXD",
        "outputId": "50efeab5-ba06-4038-891b-517d8de388fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ko6o4Si54xLM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import GRU, LSTM, SimpleRNN, Conv2D\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unMFXQv14yzo",
        "outputId": "a9de07c1-68b0-4fa9-be1a-9c8ff9f01f37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OSQbJgm45ow"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpuFq7V65TCl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d83f27f3-90c7-42c1-8e87-3c03a2d350ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pptWnCU_5bN7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d77c6b6-c34d-4c07-d864-286c54bf385f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Year                                Monitoring Location Type of Water Body  \\\n",
              "0  2022  SEA WATER, BAY OF BENGAL, AFTER CONFLUENCE OF ...             MARINE   \n",
              "1  2022  CONFLUENCE OF MARINE OUTFALL OF M/S MATRIX LAB...             MARINE   \n",
              "2  2022                     RUSHIKONDA BEACH,VISAKHAPATNAM              BEACH   \n",
              "3  2022  SEA WATER BAY BENGAL, UPPADA BEACH ROAD, KAKINADA              BEACH   \n",
              "4  2022         WATER PORT, KAKINADA (1KM AWAY FROM JETTY)                SEA   \n",
              "\n",
              "            State  Min Temp (20<)  Max Temp (>30)  Avg Temp  \\\n",
              "0  ANDHRA PRADESH            21.0            30.0      25.5   \n",
              "1  ANDHRA PRADESH            25.0            28.0      26.5   \n",
              "2  ANDHRA PRADESH            25.0            29.0      27.0   \n",
              "3  ANDHRA PRADESH            25.0            28.0      26.5   \n",
              "4  ANDHRA PRADESH            25.0            27.0      26.0   \n",
              "\n",
              "   Min Dissolved O2(mg/L)  Max Dissolved O2(mg/L)  AvgDissolved O2(mg/L)  ...  \\\n",
              "0                     5.2                     7.2                   6.20  ...   \n",
              "1                     5.2                     6.6                   5.90  ...   \n",
              "2                     4.8                     7.0                   5.90  ...   \n",
              "3                     4.5                     7.9                   6.20  ...   \n",
              "4                     5.3                     8.0                   6.65  ...   \n",
              "\n",
              "   Min BOD (mg/L)(<5)  Max BOD (mg/L)(>5)  Avg BOD  \\\n",
              "0                 1.2                 2.5     1.85   \n",
              "1                 1.4                 2.8     2.10   \n",
              "2                 1.2                 2.9     2.05   \n",
              "3                 2.2                 2.8     2.50   \n",
              "4                 2.2                 3.9     3.05   \n",
              "\n",
              "   Min NitrateN + NitriteN (mg/L)(<0.3)  Max NitrateN + NitriteN (mg/L)(>0.5)  \\\n",
              "0                                  0.32                                  1.38   \n",
              "1                                  0.32                                  0.88   \n",
              "2                                  0.32                                  1.13   \n",
              "3                                  0.42                                  1.32   \n",
              "4                                  0.82                                  3.32   \n",
              "\n",
              "   Avg NitrateN + NitriteN (mg/L)  Min Fecal Coliform (MPN/100ML)  \\\n",
              "0                           0.850                             3.0   \n",
              "1                           0.600                             3.0   \n",
              "2                           0.725                             3.0   \n",
              "3                           0.870                             3.0   \n",
              "4                           2.070                             4.0   \n",
              "\n",
              "   Max Fecal Coliform (MPN/100ML) (<200)  Avg Fecal Coliform (MPN/100ML)  \\\n",
              "0                                    7.0                             5.0   \n",
              "1                                   11.0                             7.0   \n",
              "2                                   14.0                             8.5   \n",
              "3                                   20.0                            11.5   \n",
              "4                                   23.0                            13.5   \n",
              "\n",
              "   Water Quality  \n",
              "0              0  \n",
              "1              1  \n",
              "2              1  \n",
              "3              0  \n",
              "4              0  \n",
              "\n",
              "[5 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a2dd433d-3fe1-4174-a406-a1ca99acef8c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Monitoring Location</th>\n",
              "      <th>Type of Water Body</th>\n",
              "      <th>State</th>\n",
              "      <th>Min Temp (20&lt;)</th>\n",
              "      <th>Max Temp (&gt;30)</th>\n",
              "      <th>Avg Temp</th>\n",
              "      <th>Min Dissolved O2(mg/L)</th>\n",
              "      <th>Max Dissolved O2(mg/L)</th>\n",
              "      <th>AvgDissolved O2(mg/L)</th>\n",
              "      <th>...</th>\n",
              "      <th>Min BOD (mg/L)(&lt;5)</th>\n",
              "      <th>Max BOD (mg/L)(&gt;5)</th>\n",
              "      <th>Avg BOD</th>\n",
              "      <th>Min NitrateN + NitriteN (mg/L)(&lt;0.3)</th>\n",
              "      <th>Max NitrateN + NitriteN (mg/L)(&gt;0.5)</th>\n",
              "      <th>Avg NitrateN + NitriteN (mg/L)</th>\n",
              "      <th>Min Fecal Coliform (MPN/100ML)</th>\n",
              "      <th>Max Fecal Coliform (MPN/100ML) (&lt;200)</th>\n",
              "      <th>Avg Fecal Coliform (MPN/100ML)</th>\n",
              "      <th>Water Quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022</td>\n",
              "      <td>SEA WATER, BAY OF BENGAL, AFTER CONFLUENCE OF ...</td>\n",
              "      <td>MARINE</td>\n",
              "      <td>ANDHRA PRADESH</td>\n",
              "      <td>21.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>25.5</td>\n",
              "      <td>5.2</td>\n",
              "      <td>7.2</td>\n",
              "      <td>6.20</td>\n",
              "      <td>...</td>\n",
              "      <td>1.2</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1.85</td>\n",
              "      <td>0.32</td>\n",
              "      <td>1.38</td>\n",
              "      <td>0.850</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022</td>\n",
              "      <td>CONFLUENCE OF MARINE OUTFALL OF M/S MATRIX LAB...</td>\n",
              "      <td>MARINE</td>\n",
              "      <td>ANDHRA PRADESH</td>\n",
              "      <td>25.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>26.5</td>\n",
              "      <td>5.2</td>\n",
              "      <td>6.6</td>\n",
              "      <td>5.90</td>\n",
              "      <td>...</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2.8</td>\n",
              "      <td>2.10</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.600</td>\n",
              "      <td>3.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022</td>\n",
              "      <td>RUSHIKONDA BEACH,VISAKHAPATNAM</td>\n",
              "      <td>BEACH</td>\n",
              "      <td>ANDHRA PRADESH</td>\n",
              "      <td>25.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>4.8</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.90</td>\n",
              "      <td>...</td>\n",
              "      <td>1.2</td>\n",
              "      <td>2.9</td>\n",
              "      <td>2.05</td>\n",
              "      <td>0.32</td>\n",
              "      <td>1.13</td>\n",
              "      <td>0.725</td>\n",
              "      <td>3.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>8.5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022</td>\n",
              "      <td>SEA WATER BAY BENGAL, UPPADA BEACH ROAD, KAKINADA</td>\n",
              "      <td>BEACH</td>\n",
              "      <td>ANDHRA PRADESH</td>\n",
              "      <td>25.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>26.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>7.9</td>\n",
              "      <td>6.20</td>\n",
              "      <td>...</td>\n",
              "      <td>2.2</td>\n",
              "      <td>2.8</td>\n",
              "      <td>2.50</td>\n",
              "      <td>0.42</td>\n",
              "      <td>1.32</td>\n",
              "      <td>0.870</td>\n",
              "      <td>3.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>11.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022</td>\n",
              "      <td>WATER PORT, KAKINADA (1KM AWAY FROM JETTY)</td>\n",
              "      <td>SEA</td>\n",
              "      <td>ANDHRA PRADESH</td>\n",
              "      <td>25.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>5.3</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.65</td>\n",
              "      <td>...</td>\n",
              "      <td>2.2</td>\n",
              "      <td>3.9</td>\n",
              "      <td>3.05</td>\n",
              "      <td>0.82</td>\n",
              "      <td>3.32</td>\n",
              "      <td>2.070</td>\n",
              "      <td>4.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>13.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 26 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2dd433d-3fe1-4174-a406-a1ca99acef8c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a2dd433d-3fe1-4174-a406-a1ca99acef8c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a2dd433d-3fe1-4174-a406-a1ca99acef8c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-735203d6-dada-4a41-b4fe-c6371e3318c5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-735203d6-dada-4a41-b4fe-c6371e3318c5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-735203d6-dada-4a41-b4fe-c6371e3318c5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import io\n",
        "df = pd.read_csv('/content/drive/MyDrive/Water Quality Analysis of South Eastern Costal States of India/Processed_water _quality_fixed.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kU97HUCN5bYZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64c531e7-b87c-4eff-c32f-5726f09bf304"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 216 entries, 0 to 215\n",
            "Data columns (total 26 columns):\n",
            " #   Column                                 Non-Null Count  Dtype  \n",
            "---  ------                                 --------------  -----  \n",
            " 0   Year                                   216 non-null    int64  \n",
            " 1   Monitoring Location                    216 non-null    object \n",
            " 2   Type of Water Body                     216 non-null    object \n",
            " 3   State                                  216 non-null    object \n",
            " 4   Min Temp (20<)                         216 non-null    float64\n",
            " 5   Max Temp (>30)                         216 non-null    float64\n",
            " 6   Avg Temp                               216 non-null    float64\n",
            " 7   Min Dissolved O2(mg/L)                 216 non-null    float64\n",
            " 8   Max Dissolved O2(mg/L)                 216 non-null    float64\n",
            " 9   AvgDissolved O2(mg/L)                  216 non-null    float64\n",
            " 10  Min pH(7.5<)                           216 non-null    float64\n",
            " 11  Max pH(>8.4)                           216 non-null    float64\n",
            " 12  Avg pH                                 216 non-null    float64\n",
            " 13  Min Conductivity (μmho/cm)(<30k)       216 non-null    int64  \n",
            " 14  Max Conductivity (μmho/cm)(>50k)       216 non-null    int64  \n",
            " 15  Avg Conductivity (μmho/cm)             216 non-null    float64\n",
            " 16  Min BOD (mg/L)(<5)                     216 non-null    float64\n",
            " 17  Max BOD (mg/L)(>5)                     216 non-null    float64\n",
            " 18  Avg BOD                                216 non-null    float64\n",
            " 19  Min NitrateN + NitriteN (mg/L)(<0.3)   216 non-null    float64\n",
            " 20  Max NitrateN + NitriteN (mg/L)(>0.5)   216 non-null    float64\n",
            " 21  Avg NitrateN + NitriteN (mg/L)         216 non-null    float64\n",
            " 22  Min Fecal Coliform (MPN/100ML)         216 non-null    float64\n",
            " 23  Max Fecal Coliform (MPN/100ML) (<200)  216 non-null    float64\n",
            " 24  Avg Fecal Coliform (MPN/100ML)         216 non-null    float64\n",
            " 25  Water Quality                          216 non-null    int64  \n",
            "dtypes: float64(19), int64(4), object(3)\n",
            "memory usage: 44.0+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfdgCYC19sxv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "599d9c7e-5266-45bd-dbc5-88111923d895"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(216, 26)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4S9VJ_4b-aQU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9d6ae57-7016-4530-a94a-cb9169141ec6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.isna of      Year                                Monitoring Location  \\\n",
              "0    2022  SEA WATER, BAY OF BENGAL, AFTER CONFLUENCE OF ...   \n",
              "1    2022  CONFLUENCE OF MARINE OUTFALL OF M/S MATRIX LAB...   \n",
              "2    2022                     RUSHIKONDA BEACH,VISAKHAPATNAM   \n",
              "3    2022  SEA WATER BAY BENGAL, UPPADA BEACH ROAD, KAKINADA   \n",
              "4    2022         WATER PORT, KAKINADA (1KM AWAY FROM JETTY)   \n",
              "..    ...                                                ...   \n",
              "211  2019  SEA WATER, BAY OF\\n BENGAL, VADAREVU BEACH, CH...   \n",
              "212  2019     SEA WATER, BAY OF\\n BENGAL, KRISHNAPATNAM PORT   \n",
              "213  2019  SEA WATER BAY BENGAL, UPPADA BEACH ROAD,\\n KAK...   \n",
              "214  2019  SEA WATER, BAY OF BENGAL NEAR DEEP WATER PORT,...   \n",
              "215  2019  SEA WATER BAY OF BENGAL NEAR KUMBHABHISHEKAM\\n...   \n",
              "\n",
              "    Type of Water Body           State  Min Temp (20<)  Max Temp (>30)  \\\n",
              "0               MARINE  ANDHRA PRADESH            21.0            30.0   \n",
              "1               MARINE  ANDHRA PRADESH            25.0            28.0   \n",
              "2                BEACH  ANDHRA PRADESH            25.0            29.0   \n",
              "3                BEACH  ANDHRA PRADESH            25.0            28.0   \n",
              "4                  SEA  ANDHRA PRADESH            25.0            27.0   \n",
              "..                 ...             ...             ...             ...   \n",
              "211             MARINE  ANDHRA PRADESH            23.0            30.0   \n",
              "212             MARINE  ANDHRA PRADESH            18.0            23.0   \n",
              "213                SEA  ANDHRA PRADESH            27.0            34.0   \n",
              "214                SEA  ANDHRA PRADESH            26.0            34.0   \n",
              "215                SEA  ANDHRA PRADESH            27.0            33.0   \n",
              "\n",
              "     Avg Temp  Min Dissolved O2(mg/L)  Max Dissolved O2(mg/L)  \\\n",
              "0        25.5                     5.2                     7.2   \n",
              "1        26.5                     5.2                     6.6   \n",
              "2        27.0                     4.8                     7.0   \n",
              "3        26.5                     4.5                     7.9   \n",
              "4        26.0                     5.3                     8.0   \n",
              "..        ...                     ...                     ...   \n",
              "211      26.5                     4.3                     5.7   \n",
              "212      20.5                     3.8                     6.0   \n",
              "213      30.5                     5.4                     6.6   \n",
              "214      30.0                     0.7                     5.8   \n",
              "215      30.0                     1.0                     7.5   \n",
              "\n",
              "     AvgDissolved O2(mg/L)  ...  Min BOD (mg/L)(<5)  Max BOD (mg/L)(>5)  \\\n",
              "0                     6.20  ...                 1.2                 2.5   \n",
              "1                     5.90  ...                 1.4                 2.8   \n",
              "2                     5.90  ...                 1.2                 2.9   \n",
              "3                     6.20  ...                 2.2                 2.8   \n",
              "4                     6.65  ...                 2.2                 3.9   \n",
              "..                     ...  ...                 ...                 ...   \n",
              "211                   5.00  ...                 2.2                 3.8   \n",
              "212                   4.90  ...                 2.0                 3.6   \n",
              "213                   6.00  ...                 1.6                 2.8   \n",
              "214                   3.25  ...                 1.0                 3.6   \n",
              "215                   4.25  ...                 1.1                 4.6   \n",
              "\n",
              "     Avg BOD  Min NitrateN + NitriteN (mg/L)(<0.3)  \\\n",
              "0       1.85                                  0.32   \n",
              "1       2.10                                  0.32   \n",
              "2       2.05                                  0.32   \n",
              "3       2.50                                  0.42   \n",
              "4       3.05                                  0.82   \n",
              "..       ...                                   ...   \n",
              "211     3.00                                  0.36   \n",
              "212     2.80                                  0.42   \n",
              "213     2.20                                  0.63   \n",
              "214     2.30                                  0.76   \n",
              "215     2.85                                  1.24   \n",
              "\n",
              "     Max NitrateN + NitriteN (mg/L)(>0.5)  Avg NitrateN + NitriteN (mg/L)  \\\n",
              "0                                    1.38                           0.850   \n",
              "1                                    0.88                           0.600   \n",
              "2                                    1.13                           0.725   \n",
              "3                                    1.32                           0.870   \n",
              "4                                    3.32                           2.070   \n",
              "..                                    ...                             ...   \n",
              "211                                  0.93                           0.645   \n",
              "212                                  0.97                           0.695   \n",
              "213                                  2.47                           1.550   \n",
              "214                                  4.19                           2.475   \n",
              "215                                  3.10                           2.170   \n",
              "\n",
              "     Min Fecal Coliform (MPN/100ML)  Max Fecal Coliform (MPN/100ML) (<200)  \\\n",
              "0                               3.0                                    7.0   \n",
              "1                               3.0                                   11.0   \n",
              "2                               3.0                                   14.0   \n",
              "3                               3.0                                   20.0   \n",
              "4                               4.0                                   23.0   \n",
              "..                              ...                                    ...   \n",
              "211                             3.0                                    4.0   \n",
              "212                             3.0                                    4.0   \n",
              "213                             4.0                                   20.0   \n",
              "214                             7.0                                   15.0   \n",
              "215                             7.0                                   15.0   \n",
              "\n",
              "     Avg Fecal Coliform (MPN/100ML)  Water Quality  \n",
              "0                               5.0              0  \n",
              "1                               7.0              1  \n",
              "2                               8.5              1  \n",
              "3                              11.5              0  \n",
              "4                              13.5              0  \n",
              "..                              ...            ...  \n",
              "211                             3.5              1  \n",
              "212                             3.5              1  \n",
              "213                            12.0              0  \n",
              "214                            11.0              0  \n",
              "215                            11.0              1  \n",
              "\n",
              "[216 rows x 26 columns]>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.frame.DataFrame.isna</b><br/>def isna() -&gt; DataFrame</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py</a>Detect missing values.\n",
              "\n",
              "Return a boolean same-sized object indicating if the values are NA.\n",
              "NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
              "values.\n",
              "Everything else gets mapped to False values. Characters such as empty\n",
              "strings ``&#x27;&#x27;`` or :attr:`numpy.inf` are not considered NA values\n",
              "(unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
              "\n",
              "Returns\n",
              "-------\n",
              "DataFrame\n",
              "    Mask of bool values for each element in DataFrame that\n",
              "    indicates whether an element is an NA value.\n",
              "\n",
              "See Also\n",
              "--------\n",
              "DataFrame.isnull : Alias of isna.\n",
              "DataFrame.notna : Boolean inverse of isna.\n",
              "DataFrame.dropna : Omit axes labels with missing values.\n",
              "isna : Top-level isna.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "Show which entries in a DataFrame are NA.\n",
              "\n",
              "&gt;&gt;&gt; df = pd.DataFrame(dict(age=[5, 6, np.NaN],\n",
              "...                        born=[pd.NaT, pd.Timestamp(&#x27;1939-05-27&#x27;),\n",
              "...                              pd.Timestamp(&#x27;1940-04-25&#x27;)],\n",
              "...                        name=[&#x27;Alfred&#x27;, &#x27;Batman&#x27;, &#x27;&#x27;],\n",
              "...                        toy=[None, &#x27;Batmobile&#x27;, &#x27;Joker&#x27;]))\n",
              "&gt;&gt;&gt; df\n",
              "   age       born    name        toy\n",
              "0  5.0        NaT  Alfred       None\n",
              "1  6.0 1939-05-27  Batman  Batmobile\n",
              "2  NaN 1940-04-25              Joker\n",
              "\n",
              "&gt;&gt;&gt; df.isna()\n",
              "     age   born   name    toy\n",
              "0  False   True  False   True\n",
              "1  False  False  False  False\n",
              "2   True  False  False  False\n",
              "\n",
              "Show which entries in a Series are NA.\n",
              "\n",
              "&gt;&gt;&gt; ser = pd.Series([5, 6, np.NaN])\n",
              "&gt;&gt;&gt; ser\n",
              "0    5.0\n",
              "1    6.0\n",
              "2    NaN\n",
              "dtype: float64\n",
              "\n",
              "&gt;&gt;&gt; ser.isna()\n",
              "0    False\n",
              "1    False\n",
              "2     True\n",
              "dtype: bool</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 6225);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df.isna\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4WOdWpiUYJ5"
      },
      "outputs": [],
      "source": [
        "df.drop(['Year', 'Monitoring Location', 'Type of Water Body', 'State'], axis=1, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvQ_uuSp5bg1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "440dcf97-54e5-403c-ec89-0b917a50b4fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Water Quality                            1.000000\n",
            "Min NitrateN + NitriteN (mg/L)(<0.3)     0.376754\n",
            "Avg NitrateN + NitriteN (mg/L)           0.135206\n",
            "Max Conductivity (μmho/cm)(>50k)         0.120787\n",
            "Max NitrateN + NitriteN (mg/L)(>0.5)     0.091947\n",
            "Min BOD (mg/L)(<5)                      -0.068684\n",
            "Min Fecal Coliform (MPN/100ML)          -0.072464\n",
            "Avg Conductivity (μmho/cm)              -0.111129\n",
            "Min pH(7.5<)                            -0.113683\n",
            "Max pH(>8.4)                            -0.121709\n",
            "Avg pH                                  -0.137815\n",
            "Max Fecal Coliform (MPN/100ML) (<200)   -0.152262\n",
            "Avg BOD                                 -0.152336\n",
            "Avg Fecal Coliform (MPN/100ML)          -0.154806\n",
            "Max BOD (mg/L)(>5)                      -0.165341\n",
            "Min Conductivity (μmho/cm)(<30k)        -0.169301\n",
            "Max Temp (>30)                          -0.192678\n",
            "Min Dissolved O2(mg/L)                  -0.356602\n",
            "Avg Temp                                -0.362562\n",
            "Min Temp (20<)                          -0.385768\n",
            "Max Dissolved O2(mg/L)                  -0.415700\n",
            "AvgDissolved O2(mg/L)                   -0.472543\n",
            "Name: Water Quality, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "correlation_matrix = df.corr()\n",
        "water_quality_correlation = correlation_matrix['Water Quality'].sort_values(ascending=False)\n",
        "print(water_quality_correlation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eajahk8g5bmq"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns=['Water Quality'], axis=1)   ## Features\n",
        "y = df['Water Quality']   ## target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bj-HgLuY-2lo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "093d9264-c199-4264-e66f-c1e4474f25b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape --  (183, 21)\n",
            "y_train shape --  (183,)\n",
            "X_test shape --  (33, 21)\n",
            "y_test shape --  (33,)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, shuffle=True, random_state=42)\n",
        "\n",
        "## Check Shapes of these Sets\n",
        "print('X_train shape -- ', X_train.shape)\n",
        "print('y_train shape -- ', y_train.shape)\n",
        "print('X_test shape -- ', X_test.shape)\n",
        "print('y_test shape -- ', y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzMR0lN3_nOh"
      },
      "outputs": [],
      "source": [
        "num_pipeline = Pipeline(steps=[\n",
        "                        ('imputer', SimpleImputer(strategy='median')),\n",
        "                        ('scaler', StandardScaler())\n",
        "                              ]\n",
        "                       )\n",
        "## deal with (num_pipline) as an instance -- fit and transform to train dataset and transform only to other datasets\n",
        "X_train_num = num_pipeline.fit_transform(X_train)  ## train\n",
        "X_test_num = num_pipeline.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpBZ2lvSSMsz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51ffaf96-35b8-4b98-d46d-2cd53cc6e39e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input size: 25\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/Water Quality Analysis of South Eastern Costal States of India/Processed_water _quality_fixed.csv')\n",
        "\n",
        "# Determine the input size (number of features)\n",
        "input_size = data.shape[1] - 1  # Subtract 1 for the target variable\n",
        "print(\"Input size:\", input_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGI3YLhuCvAr"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import GRU, LSTM, SimpleRNN, Conv1D, Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zANfHVJrDTg9"
      },
      "source": [
        "GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmbbTseVCxw8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e39cdcf7-c18f-4e99-d08d-798ca5b4a2ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/300], Loss: 0.6921743750572205, Accuracy: 52.00%\n",
            "Epoch [2/300], Loss: 0.6917797923088074, Accuracy: 57.00%\n",
            "Epoch [3/300], Loss: 0.6914767622947693, Accuracy: 52.00%\n",
            "Epoch [4/300], Loss: 0.6912556290626526, Accuracy: 52.00%\n",
            "Epoch [5/300], Loss: 0.691103994846344, Accuracy: 52.00%\n",
            "Epoch [6/300], Loss: 0.6910040974617004, Accuracy: 52.00%\n",
            "Epoch [7/300], Loss: 0.6909330487251282, Accuracy: 52.00%\n",
            "Epoch [8/300], Loss: 0.6908668279647827, Accuracy: 52.00%\n",
            "Epoch [9/300], Loss: 0.6907877326011658, Accuracy: 52.00%\n",
            "Epoch [10/300], Loss: 0.6906879544258118, Accuracy: 52.00%\n",
            "Epoch [11/300], Loss: 0.690569281578064, Accuracy: 52.00%\n",
            "Epoch [12/300], Loss: 0.6904390454292297, Accuracy: 52.00%\n",
            "Epoch [13/300], Loss: 0.6903060674667358, Accuracy: 52.00%\n",
            "Epoch [14/300], Loss: 0.6901781558990479, Accuracy: 52.00%\n",
            "Epoch [15/300], Loss: 0.6900596022605896, Accuracy: 52.00%\n",
            "Epoch [16/300], Loss: 0.6899516582489014, Accuracy: 52.00%\n",
            "Epoch [17/300], Loss: 0.6898515224456787, Accuracy: 51.00%\n",
            "Epoch [18/300], Loss: 0.6897541284561157, Accuracy: 53.00%\n",
            "Epoch [19/300], Loss: 0.6896536946296692, Accuracy: 55.00%\n",
            "Epoch [20/300], Loss: 0.6895456910133362, Accuracy: 56.00%\n",
            "Epoch [21/300], Loss: 0.6894283294677734, Accuracy: 56.00%\n",
            "Epoch [22/300], Loss: 0.6893027424812317, Accuracy: 56.00%\n",
            "Epoch [23/300], Loss: 0.6891722083091736, Accuracy: 56.00%\n",
            "Epoch [24/300], Loss: 0.6890410780906677, Accuracy: 56.00%\n",
            "Epoch [25/300], Loss: 0.688912570476532, Accuracy: 55.00%\n",
            "Epoch [26/300], Loss: 0.6887880563735962, Accuracy: 55.00%\n",
            "Epoch [27/300], Loss: 0.6886661052703857, Accuracy: 55.00%\n",
            "Epoch [28/300], Loss: 0.6885420083999634, Accuracy: 55.00%\n",
            "Epoch [29/300], Loss: 0.6884116530418396, Accuracy: 55.00%\n",
            "Epoch [30/300], Loss: 0.6882719397544861, Accuracy: 55.00%\n",
            "Epoch [31/300], Loss: 0.6881242394447327, Accuracy: 55.00%\n",
            "Epoch [32/300], Loss: 0.6879724264144897, Accuracy: 57.00%\n",
            "Epoch [33/300], Loss: 0.6878204345703125, Accuracy: 57.00%\n",
            "Epoch [34/300], Loss: 0.6876691579818726, Accuracy: 55.00%\n",
            "Epoch [35/300], Loss: 0.6875146627426147, Accuracy: 57.00%\n",
            "Epoch [36/300], Loss: 0.6873510479927063, Accuracy: 57.00%\n",
            "Epoch [37/300], Loss: 0.6871745586395264, Accuracy: 57.00%\n",
            "Epoch [38/300], Loss: 0.6869872212409973, Accuracy: 57.00%\n",
            "Epoch [39/300], Loss: 0.6867942810058594, Accuracy: 58.00%\n",
            "Epoch [40/300], Loss: 0.6865972280502319, Accuracy: 57.00%\n",
            "Epoch [41/300], Loss: 0.6863897442817688, Accuracy: 57.00%\n",
            "Epoch [42/300], Loss: 0.6861637234687805, Accuracy: 58.00%\n",
            "Epoch [43/300], Loss: 0.685920238494873, Accuracy: 58.00%\n",
            "Epoch [44/300], Loss: 0.685667872428894, Accuracy: 55.00%\n",
            "Epoch [45/300], Loss: 0.6854048371315002, Accuracy: 55.00%\n",
            "Epoch [46/300], Loss: 0.6851201057434082, Accuracy: 56.00%\n",
            "Epoch [47/300], Loss: 0.6848184466362, Accuracy: 56.00%\n",
            "Epoch [48/300], Loss: 0.6845176815986633, Accuracy: 56.00%\n",
            "Epoch [49/300], Loss: 0.6842136383056641, Accuracy: 57.00%\n",
            "Epoch [50/300], Loss: 0.6839196681976318, Accuracy: 59.00%\n",
            "Epoch [51/300], Loss: 0.6836727857589722, Accuracy: 58.00%\n",
            "Epoch [52/300], Loss: 0.683474600315094, Accuracy: 57.00%\n",
            "Epoch [53/300], Loss: 0.6833707690238953, Accuracy: 55.00%\n",
            "Epoch [54/300], Loss: 0.683320164680481, Accuracy: 51.00%\n",
            "Epoch [55/300], Loss: 0.6832672357559204, Accuracy: 51.00%\n",
            "Epoch [56/300], Loss: 0.6831634640693665, Accuracy: 51.00%\n",
            "Epoch [57/300], Loss: 0.6829725503921509, Accuracy: 51.00%\n",
            "Epoch [58/300], Loss: 0.6827236413955688, Accuracy: 51.00%\n",
            "Epoch [59/300], Loss: 0.6824681162834167, Accuracy: 53.00%\n",
            "Epoch [60/300], Loss: 0.6822169423103333, Accuracy: 54.00%\n",
            "Epoch [61/300], Loss: 0.6819955706596375, Accuracy: 56.00%\n",
            "Epoch [62/300], Loss: 0.6817977428436279, Accuracy: 57.00%\n",
            "Epoch [63/300], Loss: 0.6816127896308899, Accuracy: 57.00%\n",
            "Epoch [64/300], Loss: 0.681433916091919, Accuracy: 57.00%\n",
            "Epoch [65/300], Loss: 0.6812450885772705, Accuracy: 57.00%\n",
            "Epoch [66/300], Loss: 0.6810458302497864, Accuracy: 57.00%\n",
            "Epoch [67/300], Loss: 0.6808239817619324, Accuracy: 57.00%\n",
            "Epoch [68/300], Loss: 0.680584728717804, Accuracy: 56.00%\n",
            "Epoch [69/300], Loss: 0.6803221106529236, Accuracy: 56.00%\n",
            "Epoch [70/300], Loss: 0.6800428628921509, Accuracy: 56.00%\n",
            "Epoch [71/300], Loss: 0.679747998714447, Accuracy: 55.00%\n",
            "Epoch [72/300], Loss: 0.679441511631012, Accuracy: 55.00%\n",
            "Epoch [73/300], Loss: 0.679131269454956, Accuracy: 55.00%\n",
            "Epoch [74/300], Loss: 0.6788177490234375, Accuracy: 54.00%\n",
            "Epoch [75/300], Loss: 0.6784992218017578, Accuracy: 54.00%\n",
            "Epoch [76/300], Loss: 0.6781695485115051, Accuracy: 54.00%\n",
            "Epoch [77/300], Loss: 0.6778254508972168, Accuracy: 53.00%\n",
            "Epoch [78/300], Loss: 0.6774730682373047, Accuracy: 54.00%\n",
            "Epoch [79/300], Loss: 0.6771142482757568, Accuracy: 54.00%\n",
            "Epoch [80/300], Loss: 0.6767043471336365, Accuracy: 54.00%\n",
            "Epoch [81/300], Loss: 0.6762426495552063, Accuracy: 54.00%\n",
            "Epoch [82/300], Loss: 0.6758641004562378, Accuracy: 54.00%\n",
            "Epoch [83/300], Loss: 0.6754522919654846, Accuracy: 57.00%\n",
            "Epoch [84/300], Loss: 0.6749616861343384, Accuracy: 56.00%\n",
            "Epoch [85/300], Loss: 0.6745344400405884, Accuracy: 55.00%\n",
            "Epoch [86/300], Loss: 0.6740338206291199, Accuracy: 55.00%\n",
            "Epoch [87/300], Loss: 0.6734618544578552, Accuracy: 56.00%\n",
            "Epoch [88/300], Loss: 0.6729328036308289, Accuracy: 56.00%\n",
            "Epoch [89/300], Loss: 0.6723148226737976, Accuracy: 55.00%\n",
            "Epoch [90/300], Loss: 0.6716388463973999, Accuracy: 55.00%\n",
            "Epoch [91/300], Loss: 0.6710093021392822, Accuracy: 55.00%\n",
            "Epoch [92/300], Loss: 0.6703101992607117, Accuracy: 56.00%\n",
            "Epoch [93/300], Loss: 0.6695053577423096, Accuracy: 57.00%\n",
            "Epoch [94/300], Loss: 0.6687231659889221, Accuracy: 58.00%\n",
            "Epoch [95/300], Loss: 0.6679046750068665, Accuracy: 57.00%\n",
            "Epoch [96/300], Loss: 0.6669796109199524, Accuracy: 60.00%\n",
            "Epoch [97/300], Loss: 0.6660643219947815, Accuracy: 60.00%\n",
            "Epoch [98/300], Loss: 0.6651208400726318, Accuracy: 61.00%\n",
            "Epoch [99/300], Loss: 0.6640819311141968, Accuracy: 61.00%\n",
            "Epoch [100/300], Loss: 0.6630715727806091, Accuracy: 61.00%\n",
            "Epoch [101/300], Loss: 0.6620970368385315, Accuracy: 60.00%\n",
            "Epoch [102/300], Loss: 0.6611058115959167, Accuracy: 60.00%\n",
            "Epoch [103/300], Loss: 0.6602057814598083, Accuracy: 62.00%\n",
            "Epoch [104/300], Loss: 0.6594548225402832, Accuracy: 63.00%\n",
            "Epoch [105/300], Loss: 0.6588058471679688, Accuracy: 64.00%\n",
            "Epoch [106/300], Loss: 0.6582690477371216, Accuracy: 63.00%\n",
            "Epoch [107/300], Loss: 0.657776951789856, Accuracy: 62.00%\n",
            "Epoch [108/300], Loss: 0.6572045683860779, Accuracy: 62.00%\n",
            "Epoch [109/300], Loss: 0.6565112471580505, Accuracy: 62.00%\n",
            "Epoch [110/300], Loss: 0.6557334661483765, Accuracy: 62.00%\n",
            "Epoch [111/300], Loss: 0.6549410223960876, Accuracy: 62.00%\n",
            "Epoch [112/300], Loss: 0.6541865468025208, Accuracy: 62.00%\n",
            "Epoch [113/300], Loss: 0.6535301208496094, Accuracy: 62.00%\n",
            "Epoch [114/300], Loss: 0.653250515460968, Accuracy: 63.00%\n",
            "Epoch [115/300], Loss: 0.6531584858894348, Accuracy: 64.00%\n",
            "Epoch [116/300], Loss: 0.653049111366272, Accuracy: 63.00%\n",
            "Epoch [117/300], Loss: 0.6518208384513855, Accuracy: 63.00%\n",
            "Epoch [118/300], Loss: 0.6528620719909668, Accuracy: 60.00%\n",
            "Epoch [119/300], Loss: 0.6511427164077759, Accuracy: 63.00%\n",
            "Epoch [120/300], Loss: 0.6515641808509827, Accuracy: 64.00%\n",
            "Epoch [121/300], Loss: 0.6496840119361877, Accuracy: 64.00%\n",
            "Epoch [122/300], Loss: 0.6510128974914551, Accuracy: 61.00%\n",
            "Epoch [123/300], Loss: 0.6489691734313965, Accuracy: 66.00%\n",
            "Epoch [124/300], Loss: 0.6497129797935486, Accuracy: 66.00%\n",
            "Epoch [125/300], Loss: 0.6476679444313049, Accuracy: 66.00%\n",
            "Epoch [126/300], Loss: 0.6493126749992371, Accuracy: 62.00%\n",
            "Epoch [127/300], Loss: 0.6468174457550049, Accuracy: 67.00%\n",
            "Epoch [128/300], Loss: 0.6476932764053345, Accuracy: 66.00%\n",
            "Epoch [129/300], Loss: 0.6457089185714722, Accuracy: 67.00%\n",
            "Epoch [130/300], Loss: 0.6468837261199951, Accuracy: 62.00%\n",
            "Epoch [131/300], Loss: 0.6445140838623047, Accuracy: 68.00%\n",
            "Epoch [132/300], Loss: 0.6451341509819031, Accuracy: 67.00%\n",
            "Epoch [133/300], Loss: 0.6436320543289185, Accuracy: 69.00%\n",
            "Epoch [134/300], Loss: 0.6439498662948608, Accuracy: 63.00%\n",
            "Epoch [135/300], Loss: 0.6422667503356934, Accuracy: 67.00%\n",
            "Epoch [136/300], Loss: 0.6424475908279419, Accuracy: 67.00%\n",
            "Epoch [137/300], Loss: 0.6411997079849243, Accuracy: 68.00%\n",
            "Epoch [138/300], Loss: 0.6414206624031067, Accuracy: 63.00%\n",
            "Epoch [139/300], Loss: 0.6399658918380737, Accuracy: 67.00%\n",
            "Epoch [140/300], Loss: 0.6398301124572754, Accuracy: 67.00%\n",
            "Epoch [141/300], Loss: 0.6387118697166443, Accuracy: 66.00%\n",
            "Epoch [142/300], Loss: 0.6382894515991211, Accuracy: 66.00%\n",
            "Epoch [143/300], Loss: 0.6377434730529785, Accuracy: 67.00%\n",
            "Epoch [144/300], Loss: 0.636691153049469, Accuracy: 68.00%\n",
            "Epoch [145/300], Loss: 0.6366193890571594, Accuracy: 66.00%\n",
            "Epoch [146/300], Loss: 0.6354349255561829, Accuracy: 70.00%\n",
            "Epoch [147/300], Loss: 0.6346868872642517, Accuracy: 69.00%\n",
            "Epoch [148/300], Loss: 0.6342868208885193, Accuracy: 65.00%\n",
            "Epoch [149/300], Loss: 0.6330023407936096, Accuracy: 69.00%\n",
            "Epoch [150/300], Loss: 0.6322466135025024, Accuracy: 69.00%\n",
            "Epoch [151/300], Loss: 0.6316635012626648, Accuracy: 66.00%\n",
            "Epoch [152/300], Loss: 0.6304618716239929, Accuracy: 69.00%\n",
            "Epoch [153/300], Loss: 0.6294096112251282, Accuracy: 68.00%\n",
            "Epoch [154/300], Loss: 0.6287882328033447, Accuracy: 67.00%\n",
            "Epoch [155/300], Loss: 0.6277899742126465, Accuracy: 69.00%\n",
            "Epoch [156/300], Loss: 0.6262115240097046, Accuracy: 69.00%\n",
            "Epoch [157/300], Loss: 0.6252620816230774, Accuracy: 66.00%\n",
            "Epoch [158/300], Loss: 0.6245288252830505, Accuracy: 66.00%\n",
            "Epoch [159/300], Loss: 0.6228031516075134, Accuracy: 65.00%\n",
            "Epoch [160/300], Loss: 0.6211193203926086, Accuracy: 66.00%\n",
            "Epoch [161/300], Loss: 0.6197527050971985, Accuracy: 66.00%\n",
            "Epoch [162/300], Loss: 0.618518590927124, Accuracy: 66.00%\n",
            "Epoch [163/300], Loss: 0.6174364686012268, Accuracy: 67.00%\n",
            "Epoch [164/300], Loss: 0.6155405640602112, Accuracy: 66.00%\n",
            "Epoch [165/300], Loss: 0.6138452887535095, Accuracy: 70.00%\n",
            "Epoch [166/300], Loss: 0.6115952134132385, Accuracy: 67.00%\n",
            "Epoch [167/300], Loss: 0.6095547080039978, Accuracy: 67.00%\n",
            "Epoch [168/300], Loss: 0.6075880527496338, Accuracy: 66.00%\n",
            "Epoch [169/300], Loss: 0.6056739687919617, Accuracy: 66.00%\n",
            "Epoch [170/300], Loss: 0.603902280330658, Accuracy: 67.00%\n",
            "Epoch [171/300], Loss: 0.603262186050415, Accuracy: 64.00%\n",
            "Epoch [172/300], Loss: 0.609315812587738, Accuracy: 67.00%\n",
            "Epoch [173/300], Loss: 0.5989440679550171, Accuracy: 67.00%\n",
            "Epoch [174/300], Loss: 0.6033504009246826, Accuracy: 63.00%\n",
            "Epoch [175/300], Loss: 0.6115729808807373, Accuracy: 66.00%\n",
            "Epoch [176/300], Loss: 0.6070529222488403, Accuracy: 66.00%\n",
            "Epoch [177/300], Loss: 0.5966331958770752, Accuracy: 66.00%\n",
            "Epoch [178/300], Loss: 0.5960931181907654, Accuracy: 63.00%\n",
            "Epoch [179/300], Loss: 0.5988647937774658, Accuracy: 64.00%\n",
            "Epoch [180/300], Loss: 0.59878009557724, Accuracy: 64.00%\n",
            "Epoch [181/300], Loss: 0.5861761569976807, Accuracy: 67.00%\n",
            "Epoch [182/300], Loss: 0.5944984555244446, Accuracy: 63.00%\n",
            "Epoch [183/300], Loss: 0.5978363156318665, Accuracy: 65.00%\n",
            "Epoch [184/300], Loss: 0.604658305644989, Accuracy: 64.00%\n",
            "Epoch [185/300], Loss: 0.5895928740501404, Accuracy: 69.00%\n",
            "Epoch [186/300], Loss: 0.6011536121368408, Accuracy: 67.00%\n",
            "Epoch [187/300], Loss: 0.5927441120147705, Accuracy: 66.00%\n",
            "Epoch [188/300], Loss: 0.589479923248291, Accuracy: 67.00%\n",
            "Epoch [189/300], Loss: 0.5951165556907654, Accuracy: 64.00%\n",
            "Epoch [190/300], Loss: 0.5849080085754395, Accuracy: 67.00%\n",
            "Epoch [191/300], Loss: 0.5872467160224915, Accuracy: 66.00%\n",
            "Epoch [192/300], Loss: 0.5860329270362854, Accuracy: 66.00%\n",
            "Epoch [193/300], Loss: 0.5791241526603699, Accuracy: 67.00%\n",
            "Epoch [194/300], Loss: 0.583156406879425, Accuracy: 65.00%\n",
            "Epoch [195/300], Loss: 0.5751379132270813, Accuracy: 68.00%\n",
            "Epoch [196/300], Loss: 0.5775873064994812, Accuracy: 65.00%\n",
            "Epoch [197/300], Loss: 0.5674629807472229, Accuracy: 67.00%\n",
            "Epoch [198/300], Loss: 0.569552481174469, Accuracy: 70.00%\n",
            "Epoch [199/300], Loss: 0.5645503997802734, Accuracy: 69.00%\n",
            "Epoch [200/300], Loss: 0.5622553825378418, Accuracy: 68.00%\n",
            "Epoch [201/300], Loss: 0.5624584555625916, Accuracy: 69.00%\n",
            "Epoch [202/300], Loss: 0.5590648055076599, Accuracy: 68.00%\n",
            "Epoch [203/300], Loss: 0.5603550672531128, Accuracy: 68.00%\n",
            "Epoch [204/300], Loss: 0.557818591594696, Accuracy: 68.00%\n",
            "Epoch [205/300], Loss: 0.5560548305511475, Accuracy: 68.00%\n",
            "Epoch [206/300], Loss: 0.5583657026290894, Accuracy: 66.00%\n",
            "Epoch [207/300], Loss: 0.5558696985244751, Accuracy: 67.00%\n",
            "Epoch [208/300], Loss: 0.5551633238792419, Accuracy: 66.00%\n",
            "Epoch [209/300], Loss: 0.5517703294754028, Accuracy: 67.00%\n",
            "Epoch [210/300], Loss: 0.5515642762184143, Accuracy: 66.00%\n",
            "Epoch [211/300], Loss: 0.550190806388855, Accuracy: 68.00%\n",
            "Epoch [212/300], Loss: 0.547106921672821, Accuracy: 67.00%\n",
            "Epoch [213/300], Loss: 0.5567319989204407, Accuracy: 66.00%\n",
            "Epoch [214/300], Loss: 0.5508317947387695, Accuracy: 67.00%\n",
            "Epoch [215/300], Loss: 0.5543394088745117, Accuracy: 67.00%\n",
            "Epoch [216/300], Loss: 0.5537864565849304, Accuracy: 67.00%\n",
            "Epoch [217/300], Loss: 0.5551816821098328, Accuracy: 66.00%\n",
            "Epoch [218/300], Loss: 0.5506302118301392, Accuracy: 67.00%\n",
            "Epoch [219/300], Loss: 0.5526098012924194, Accuracy: 68.00%\n",
            "Epoch [220/300], Loss: 0.5483523607254028, Accuracy: 67.00%\n",
            "Epoch [221/300], Loss: 0.5487171411514282, Accuracy: 66.00%\n",
            "Epoch [222/300], Loss: 0.5461629629135132, Accuracy: 69.00%\n",
            "Epoch [223/300], Loss: 0.5445499420166016, Accuracy: 70.00%\n",
            "Epoch [224/300], Loss: 0.543720006942749, Accuracy: 71.00%\n",
            "Epoch [225/300], Loss: 0.5408027172088623, Accuracy: 68.00%\n",
            "Epoch [226/300], Loss: 0.5408715605735779, Accuracy: 68.00%\n",
            "Epoch [227/300], Loss: 0.5376904606819153, Accuracy: 71.00%\n",
            "Epoch [228/300], Loss: 0.5376890897750854, Accuracy: 71.00%\n",
            "Epoch [229/300], Loss: 0.5347559452056885, Accuracy: 71.00%\n",
            "Epoch [230/300], Loss: 0.5344213247299194, Accuracy: 69.00%\n",
            "Epoch [231/300], Loss: 0.5317786931991577, Accuracy: 72.00%\n",
            "Epoch [232/300], Loss: 0.5310252904891968, Accuracy: 71.00%\n",
            "Epoch [233/300], Loss: 0.5287240743637085, Accuracy: 72.00%\n",
            "Epoch [234/300], Loss: 0.5276612043380737, Accuracy: 73.00%\n",
            "Epoch [235/300], Loss: 0.525605320930481, Accuracy: 73.00%\n",
            "Epoch [236/300], Loss: 0.524368941783905, Accuracy: 72.00%\n",
            "Epoch [237/300], Loss: 0.5224707126617432, Accuracy: 73.00%\n",
            "Epoch [238/300], Loss: 0.5211471319198608, Accuracy: 72.00%\n",
            "Epoch [239/300], Loss: 0.5193029642105103, Accuracy: 73.00%\n",
            "Epoch [240/300], Loss: 0.5179763436317444, Accuracy: 74.00%\n",
            "Epoch [241/300], Loss: 0.5161076784133911, Accuracy: 74.00%\n",
            "Epoch [242/300], Loss: 0.5147721171379089, Accuracy: 74.00%\n",
            "Epoch [243/300], Loss: 0.5128248333930969, Accuracy: 74.00%\n",
            "Epoch [244/300], Loss: 0.5114901661872864, Accuracy: 75.00%\n",
            "Epoch [245/300], Loss: 0.5095385909080505, Accuracy: 75.00%\n",
            "Epoch [246/300], Loss: 0.5082100629806519, Accuracy: 76.00%\n",
            "Epoch [247/300], Loss: 0.5063163638114929, Accuracy: 76.00%\n",
            "Epoch [248/300], Loss: 0.5049330592155457, Accuracy: 75.00%\n",
            "Epoch [249/300], Loss: 0.5031630992889404, Accuracy: 75.00%\n",
            "Epoch [250/300], Loss: 0.5016508102416992, Accuracy: 75.00%\n",
            "Epoch [251/300], Loss: 0.5000236630439758, Accuracy: 76.00%\n",
            "Epoch [252/300], Loss: 0.4983503818511963, Accuracy: 76.00%\n",
            "Epoch [253/300], Loss: 0.49685582518577576, Accuracy: 76.00%\n",
            "Epoch [254/300], Loss: 0.49509936571121216, Accuracy: 76.00%\n",
            "Epoch [255/300], Loss: 0.493613064289093, Accuracy: 76.00%\n",
            "Epoch [256/300], Loss: 0.49192702770233154, Accuracy: 76.00%\n",
            "Epoch [257/300], Loss: 0.49033188819885254, Accuracy: 76.00%\n",
            "Epoch [258/300], Loss: 0.4887891709804535, Accuracy: 76.00%\n",
            "Epoch [259/300], Loss: 0.4871036410331726, Accuracy: 76.00%\n",
            "Epoch [260/300], Loss: 0.48558154702186584, Accuracy: 77.00%\n",
            "Epoch [261/300], Loss: 0.4839547872543335, Accuracy: 77.00%\n",
            "Epoch [262/300], Loss: 0.4823180139064789, Accuracy: 78.00%\n",
            "Epoch [263/300], Loss: 0.480779767036438, Accuracy: 79.00%\n",
            "Epoch [264/300], Loss: 0.4791322350502014, Accuracy: 79.00%\n",
            "Epoch [265/300], Loss: 0.47752106189727783, Accuracy: 79.00%\n",
            "Epoch [266/300], Loss: 0.4759599566459656, Accuracy: 79.00%\n",
            "Epoch [267/300], Loss: 0.4743121862411499, Accuracy: 79.00%\n",
            "Epoch [268/300], Loss: 0.47268760204315186, Accuracy: 79.00%\n",
            "Epoch [269/300], Loss: 0.4711158275604248, Accuracy: 79.00%\n",
            "Epoch [270/300], Loss: 0.46951010823249817, Accuracy: 79.00%\n",
            "Epoch [271/300], Loss: 0.4679197669029236, Accuracy: 79.00%\n",
            "Epoch [272/300], Loss: 0.4663970172405243, Accuracy: 79.00%\n",
            "Epoch [273/300], Loss: 0.46485480666160583, Accuracy: 78.00%\n",
            "Epoch [274/300], Loss: 0.46325093507766724, Accuracy: 78.00%\n",
            "Epoch [275/300], Loss: 0.46164461970329285, Accuracy: 79.00%\n",
            "Epoch [276/300], Loss: 0.46007370948791504, Accuracy: 79.00%\n",
            "Epoch [277/300], Loss: 0.4585084617137909, Accuracy: 79.00%\n",
            "Epoch [278/300], Loss: 0.4569106996059418, Accuracy: 78.00%\n",
            "Epoch [279/300], Loss: 0.4552799165248871, Accuracy: 79.00%\n",
            "Epoch [280/300], Loss: 0.4536483883857727, Accuracy: 79.00%\n",
            "Epoch [281/300], Loss: 0.4520193040370941, Accuracy: 79.00%\n",
            "Epoch [282/300], Loss: 0.4503742456436157, Accuracy: 79.00%\n",
            "Epoch [283/300], Loss: 0.4487093985080719, Accuracy: 79.00%\n",
            "Epoch [284/300], Loss: 0.4470405876636505, Accuracy: 80.00%\n",
            "Epoch [285/300], Loss: 0.44536179304122925, Accuracy: 80.00%\n",
            "Epoch [286/300], Loss: 0.4436541795730591, Accuracy: 80.00%\n",
            "Epoch [287/300], Loss: 0.4419146776199341, Accuracy: 80.00%\n",
            "Epoch [288/300], Loss: 0.4401574432849884, Accuracy: 80.00%\n",
            "Epoch [289/300], Loss: 0.4383913278579712, Accuracy: 80.00%\n",
            "Epoch [290/300], Loss: 0.43662193417549133, Accuracy: 80.00%\n",
            "Epoch [291/300], Loss: 0.43492087721824646, Accuracy: 80.00%\n",
            "Epoch [292/300], Loss: 0.43367549777030945, Accuracy: 81.00%\n",
            "Epoch [293/300], Loss: 0.4346961975097656, Accuracy: 80.00%\n",
            "Epoch [294/300], Loss: 0.44665417075157166, Accuracy: 77.00%\n",
            "Epoch [295/300], Loss: 0.4786494970321655, Accuracy: 74.00%\n",
            "Epoch [296/300], Loss: 0.4447692632675171, Accuracy: 76.00%\n",
            "Epoch [297/300], Loss: 0.4306519627571106, Accuracy: 81.00%\n",
            "Epoch [298/300], Loss: 0.45320361852645874, Accuracy: 75.00%\n",
            "Epoch [299/300], Loss: 0.4267987012863159, Accuracy: 81.00%\n",
            "Epoch [300/300], Loss: 0.4381738305091858, Accuracy: 76.00%\n",
            "Confusion Matrix:\n",
            "[[37 11]\n",
            " [13 39]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Set the random seed for NumPy\n",
        "np.random.seed(42)\n",
        "\n",
        "# Set the random seed for PyTorch\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Define your data\n",
        "X_train_num = np.random.rand(100, 9, 1)\n",
        "y_train = np.random.randint(0, 2, size=(100, 1))\n",
        "\n",
        "# Convert NumPy arrays to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train_num, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "\n",
        "# Define the GRU model\n",
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(GRUModel, self).__init__()\n",
        "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.gru(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Create the GRU model\n",
        "input_size = 1\n",
        "hidden_size = 64\n",
        "output_size = 1\n",
        "model = GRUModel(input_size, hidden_size, output_size)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()  # Binary cross-entropy loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Function to calculate accuracy\n",
        "def calculate_accuracy(outputs, labels):\n",
        "    preds = (outputs >= 0.5).to(torch.float32)\n",
        "    correct = (preds == labels).sum().item()\n",
        "    total = labels.size(0)\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 300\n",
        "for epoch in range(num_epochs):\n",
        "    outputs = model(X_train_tensor)\n",
        "    loss = criterion(outputs, y_train_tensor)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    accuracy = calculate_accuracy(torch.sigmoid(outputs), y_train_tensor)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}, Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Calculate and print the confusion matrix\n",
        "y_pred = (torch.sigmoid(outputs) >= 0.5).squeeze().numpy()\n",
        "y_true = y_train.squeeze()\n",
        "confusion = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "450l65YGiLkA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5d74fbe-aeae-4397-eaaa-22b211c8e77d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualize the confusion matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion, annot=True, fmt=\"d\", cmap=\"Pastel1\", xticklabels=[\"Predicted 0\", \"Predicted 1\"], yticklabels=[\"Actual 0\", \"Actual 1\"])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix (percentages)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score,recall_score\n",
        "\n",
        "y_true = [0]*37 + [1]*11 + [0]*13 + [1]*39\n",
        "y_pred = [0]*37+ [0]*13 + [1]*11 + [1]*39\n",
        "\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "print(\"Precision:\", precision)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDQ6kpZZLg7U",
        "outputId": "ed32413f-e3cb-408c-9d69-7b2ad67e652a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Recall\",43/(38+43))"
      ],
      "metadata": {
        "id": "1q4EWecETQyC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "954e465d-2629-4e5b-e6ef-c20e41077e8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall 0.5308641975308642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10gXZ0wRocl6"
      },
      "source": [
        "LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTzkkQArDhTZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a11e6a6b-ea9c-4b02-f498-522a8b3a60ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/300], Loss: 0.6924824714660645, Accuracy: 52.00%\n",
            "Epoch [2/300], Loss: 0.692400336265564, Accuracy: 52.00%\n",
            "Epoch [3/300], Loss: 0.6923249959945679, Accuracy: 52.00%\n",
            "Epoch [4/300], Loss: 0.6922479271888733, Accuracy: 52.00%\n",
            "Epoch [5/300], Loss: 0.6921699643135071, Accuracy: 52.00%\n",
            "Epoch [6/300], Loss: 0.6920923590660095, Accuracy: 52.00%\n",
            "Epoch [7/300], Loss: 0.6920154094696045, Accuracy: 52.00%\n",
            "Epoch [8/300], Loss: 0.691938042640686, Accuracy: 52.00%\n",
            "Epoch [9/300], Loss: 0.6918594837188721, Accuracy: 52.00%\n",
            "Epoch [10/300], Loss: 0.691780149936676, Accuracy: 52.00%\n",
            "Epoch [11/300], Loss: 0.6916999816894531, Accuracy: 52.00%\n",
            "Epoch [12/300], Loss: 0.6916192770004272, Accuracy: 52.00%\n",
            "Epoch [13/300], Loss: 0.6915371417999268, Accuracy: 52.00%\n",
            "Epoch [14/300], Loss: 0.691453218460083, Accuracy: 52.00%\n",
            "Epoch [15/300], Loss: 0.6913672685623169, Accuracy: 52.00%\n",
            "Epoch [16/300], Loss: 0.6912789344787598, Accuracy: 52.00%\n",
            "Epoch [17/300], Loss: 0.6911882162094116, Accuracy: 52.00%\n",
            "Epoch [18/300], Loss: 0.6910943388938904, Accuracy: 52.00%\n",
            "Epoch [19/300], Loss: 0.6909964084625244, Accuracy: 52.00%\n",
            "Epoch [20/300], Loss: 0.6908938884735107, Accuracy: 52.00%\n",
            "Epoch [21/300], Loss: 0.6907863616943359, Accuracy: 52.00%\n",
            "Epoch [22/300], Loss: 0.690672755241394, Accuracy: 52.00%\n",
            "Epoch [23/300], Loss: 0.6905518174171448, Accuracy: 52.00%\n",
            "Epoch [24/300], Loss: 0.6904221177101135, Accuracy: 52.00%\n",
            "Epoch [25/300], Loss: 0.6902824640274048, Accuracy: 52.00%\n",
            "Epoch [26/300], Loss: 0.6901309490203857, Accuracy: 53.00%\n",
            "Epoch [27/300], Loss: 0.6899651288986206, Accuracy: 54.00%\n",
            "Epoch [28/300], Loss: 0.6897830963134766, Accuracy: 53.00%\n",
            "Epoch [29/300], Loss: 0.6895817518234253, Accuracy: 53.00%\n",
            "Epoch [30/300], Loss: 0.6893580555915833, Accuracy: 54.00%\n",
            "Epoch [31/300], Loss: 0.6891093254089355, Accuracy: 55.00%\n",
            "Epoch [32/300], Loss: 0.6888329982757568, Accuracy: 55.00%\n",
            "Epoch [33/300], Loss: 0.6885278820991516, Accuracy: 53.00%\n",
            "Epoch [34/300], Loss: 0.6881951093673706, Accuracy: 54.00%\n",
            "Epoch [35/300], Loss: 0.6878409385681152, Accuracy: 54.00%\n",
            "Epoch [36/300], Loss: 0.6874816417694092, Accuracy: 56.00%\n",
            "Epoch [37/300], Loss: 0.6871485710144043, Accuracy: 57.00%\n",
            "Epoch [38/300], Loss: 0.6868981122970581, Accuracy: 57.00%\n",
            "Epoch [39/300], Loss: 0.6868452429771423, Accuracy: 55.00%\n",
            "Epoch [40/300], Loss: 0.6872830390930176, Accuracy: 51.00%\n",
            "Epoch [41/300], Loss: 0.6869046092033386, Accuracy: 55.00%\n",
            "Epoch [42/300], Loss: 0.687197744846344, Accuracy: 53.00%\n",
            "Epoch [43/300], Loss: 0.6867563724517822, Accuracy: 53.00%\n",
            "Epoch [44/300], Loss: 0.6868961453437805, Accuracy: 52.00%\n",
            "Epoch [45/300], Loss: 0.6866216063499451, Accuracy: 54.00%\n",
            "Epoch [46/300], Loss: 0.6864110827445984, Accuracy: 54.00%\n",
            "Epoch [47/300], Loss: 0.6864480376243591, Accuracy: 56.00%\n",
            "Epoch [48/300], Loss: 0.6862152814865112, Accuracy: 57.00%\n",
            "Epoch [49/300], Loss: 0.6861007809638977, Accuracy: 52.00%\n",
            "Epoch [50/300], Loss: 0.686122715473175, Accuracy: 51.00%\n",
            "Epoch [51/300], Loss: 0.6859955787658691, Accuracy: 50.00%\n",
            "Epoch [52/300], Loss: 0.6858834624290466, Accuracy: 56.00%\n",
            "Epoch [53/300], Loss: 0.6858873963356018, Accuracy: 58.00%\n",
            "Epoch [54/300], Loss: 0.6858230829238892, Accuracy: 58.00%\n",
            "Epoch [55/300], Loss: 0.685699999332428, Accuracy: 58.00%\n",
            "Epoch [56/300], Loss: 0.6856509447097778, Accuracy: 53.00%\n",
            "Epoch [57/300], Loss: 0.6856045722961426, Accuracy: 51.00%\n",
            "Epoch [58/300], Loss: 0.6854842901229858, Accuracy: 54.00%\n",
            "Epoch [59/300], Loss: 0.685384213924408, Accuracy: 58.00%\n",
            "Epoch [60/300], Loss: 0.6853256821632385, Accuracy: 58.00%\n",
            "Epoch [61/300], Loss: 0.6852133274078369, Accuracy: 58.00%\n",
            "Epoch [62/300], Loss: 0.6850912570953369, Accuracy: 55.00%\n",
            "Epoch [63/300], Loss: 0.6850171089172363, Accuracy: 51.00%\n",
            "Epoch [64/300], Loss: 0.684909462928772, Accuracy: 51.00%\n",
            "Epoch [65/300], Loss: 0.6847891211509705, Accuracy: 55.00%\n",
            "Epoch [66/300], Loss: 0.6847142577171326, Accuracy: 56.00%\n",
            "Epoch [67/300], Loss: 0.6846039295196533, Accuracy: 55.00%\n",
            "Epoch [68/300], Loss: 0.6844990253448486, Accuracy: 50.00%\n",
            "Epoch [69/300], Loss: 0.6844188570976257, Accuracy: 51.00%\n",
            "Epoch [70/300], Loss: 0.6842995285987854, Accuracy: 51.00%\n",
            "Epoch [71/300], Loss: 0.6842082738876343, Accuracy: 52.00%\n",
            "Epoch [72/300], Loss: 0.6840980648994446, Accuracy: 51.00%\n",
            "Epoch [73/300], Loss: 0.6839795112609863, Accuracy: 51.00%\n",
            "Epoch [74/300], Loss: 0.6838738918304443, Accuracy: 49.00%\n",
            "Epoch [75/300], Loss: 0.6837399005889893, Accuracy: 52.00%\n",
            "Epoch [76/300], Loss: 0.6836278438568115, Accuracy: 52.00%\n",
            "Epoch [77/300], Loss: 0.6834927201271057, Accuracy: 51.00%\n",
            "Epoch [78/300], Loss: 0.683368980884552, Accuracy: 50.00%\n",
            "Epoch [79/300], Loss: 0.6832374334335327, Accuracy: 50.00%\n",
            "Epoch [80/300], Loss: 0.6831021308898926, Accuracy: 51.00%\n",
            "Epoch [81/300], Loss: 0.682969868183136, Accuracy: 51.00%\n",
            "Epoch [82/300], Loss: 0.6828234791755676, Accuracy: 50.00%\n",
            "Epoch [83/300], Loss: 0.6826831698417664, Accuracy: 50.00%\n",
            "Epoch [84/300], Loss: 0.682525098323822, Accuracy: 50.00%\n",
            "Epoch [85/300], Loss: 0.6823721528053284, Accuracy: 51.00%\n",
            "Epoch [86/300], Loss: 0.682201087474823, Accuracy: 50.00%\n",
            "Epoch [87/300], Loss: 0.6820333003997803, Accuracy: 49.00%\n",
            "Epoch [88/300], Loss: 0.6818488836288452, Accuracy: 50.00%\n",
            "Epoch [89/300], Loss: 0.6816661357879639, Accuracy: 50.00%\n",
            "Epoch [90/300], Loss: 0.681467592716217, Accuracy: 49.00%\n",
            "Epoch [91/300], Loss: 0.6812660694122314, Accuracy: 49.00%\n",
            "Epoch [92/300], Loss: 0.6810521483421326, Accuracy: 49.00%\n",
            "Epoch [93/300], Loss: 0.6808252930641174, Accuracy: 49.00%\n",
            "Epoch [94/300], Loss: 0.6805901527404785, Accuracy: 50.00%\n",
            "Epoch [95/300], Loss: 0.6803354620933533, Accuracy: 51.00%\n",
            "Epoch [96/300], Loss: 0.6800678968429565, Accuracy: 51.00%\n",
            "Epoch [97/300], Loss: 0.679786205291748, Accuracy: 51.00%\n",
            "Epoch [98/300], Loss: 0.6794829368591309, Accuracy: 51.00%\n",
            "Epoch [99/300], Loss: 0.6791613698005676, Accuracy: 52.00%\n",
            "Epoch [100/300], Loss: 0.6788207292556763, Accuracy: 51.00%\n",
            "Epoch [101/300], Loss: 0.678454577922821, Accuracy: 52.00%\n",
            "Epoch [102/300], Loss: 0.6780604720115662, Accuracy: 51.00%\n",
            "Epoch [103/300], Loss: 0.6776381731033325, Accuracy: 51.00%\n",
            "Epoch [104/300], Loss: 0.6771878004074097, Accuracy: 50.00%\n",
            "Epoch [105/300], Loss: 0.6767082214355469, Accuracy: 49.00%\n",
            "Epoch [106/300], Loss: 0.6761994361877441, Accuracy: 50.00%\n",
            "Epoch [107/300], Loss: 0.6756665110588074, Accuracy: 50.00%\n",
            "Epoch [108/300], Loss: 0.6751329898834229, Accuracy: 52.00%\n",
            "Epoch [109/300], Loss: 0.6746780276298523, Accuracy: 52.00%\n",
            "Epoch [110/300], Loss: 0.6743006110191345, Accuracy: 54.00%\n",
            "Epoch [111/300], Loss: 0.6738389730453491, Accuracy: 54.00%\n",
            "Epoch [112/300], Loss: 0.6729815602302551, Accuracy: 57.00%\n",
            "Epoch [113/300], Loss: 0.6728411912918091, Accuracy: 58.00%\n",
            "Epoch [114/300], Loss: 0.6723663210868835, Accuracy: 56.00%\n",
            "Epoch [115/300], Loss: 0.6716551780700684, Accuracy: 56.00%\n",
            "Epoch [116/300], Loss: 0.67158043384552, Accuracy: 56.00%\n",
            "Epoch [117/300], Loss: 0.6707144379615784, Accuracy: 56.00%\n",
            "Epoch [118/300], Loss: 0.670468807220459, Accuracy: 57.00%\n",
            "Epoch [119/300], Loss: 0.6697238087654114, Accuracy: 54.00%\n",
            "Epoch [120/300], Loss: 0.6693471670150757, Accuracy: 54.00%\n",
            "Epoch [121/300], Loss: 0.6686570048332214, Accuracy: 57.00%\n",
            "Epoch [122/300], Loss: 0.6680690050125122, Accuracy: 61.00%\n",
            "Epoch [123/300], Loss: 0.6673558950424194, Accuracy: 58.00%\n",
            "Epoch [124/300], Loss: 0.6665951609611511, Accuracy: 57.00%\n",
            "Epoch [125/300], Loss: 0.6659020185470581, Accuracy: 61.00%\n",
            "Epoch [126/300], Loss: 0.6649878621101379, Accuracy: 62.00%\n",
            "Epoch [127/300], Loss: 0.6642908453941345, Accuracy: 59.00%\n",
            "Epoch [128/300], Loss: 0.663254976272583, Accuracy: 62.00%\n",
            "Epoch [129/300], Loss: 0.6624186038970947, Accuracy: 62.00%\n",
            "Epoch [130/300], Loss: 0.6614618897438049, Accuracy: 58.00%\n",
            "Epoch [131/300], Loss: 0.660371720790863, Accuracy: 62.00%\n",
            "Epoch [132/300], Loss: 0.6593921184539795, Accuracy: 61.00%\n",
            "Epoch [133/300], Loss: 0.6582577228546143, Accuracy: 60.00%\n",
            "Epoch [134/300], Loss: 0.6570420265197754, Accuracy: 62.00%\n",
            "Epoch [135/300], Loss: 0.6558894515037537, Accuracy: 62.00%\n",
            "Epoch [136/300], Loss: 0.6547682285308838, Accuracy: 60.00%\n",
            "Epoch [137/300], Loss: 0.653678297996521, Accuracy: 63.00%\n",
            "Epoch [138/300], Loss: 0.652584969997406, Accuracy: 59.00%\n",
            "Epoch [139/300], Loss: 0.6515668630599976, Accuracy: 62.00%\n",
            "Epoch [140/300], Loss: 0.6505745053291321, Accuracy: 60.00%\n",
            "Epoch [141/300], Loss: 0.6496134400367737, Accuracy: 66.00%\n",
            "Epoch [142/300], Loss: 0.6488000750541687, Accuracy: 62.00%\n",
            "Epoch [143/300], Loss: 0.649146556854248, Accuracy: 63.00%\n",
            "Epoch [144/300], Loss: 0.6466972827911377, Accuracy: 61.00%\n",
            "Epoch [145/300], Loss: 0.6443865895271301, Accuracy: 65.00%\n",
            "Epoch [146/300], Loss: 0.6432159543037415, Accuracy: 65.00%\n",
            "Epoch [147/300], Loss: 0.6421163082122803, Accuracy: 64.00%\n",
            "Epoch [148/300], Loss: 0.6403877139091492, Accuracy: 66.00%\n",
            "Epoch [149/300], Loss: 0.6384236812591553, Accuracy: 67.00%\n",
            "Epoch [150/300], Loss: 0.6374474167823792, Accuracy: 64.00%\n",
            "Epoch [151/300], Loss: 0.6362237334251404, Accuracy: 67.00%\n",
            "Epoch [152/300], Loss: 0.6331433057785034, Accuracy: 65.00%\n",
            "Epoch [153/300], Loss: 0.6317947506904602, Accuracy: 64.00%\n",
            "Epoch [154/300], Loss: 0.6312504410743713, Accuracy: 66.00%\n",
            "Epoch [155/300], Loss: 0.6276639103889465, Accuracy: 65.00%\n",
            "Epoch [156/300], Loss: 0.6253917217254639, Accuracy: 66.00%\n",
            "Epoch [157/300], Loss: 0.6249966621398926, Accuracy: 67.00%\n",
            "Epoch [158/300], Loss: 0.6235346794128418, Accuracy: 63.00%\n",
            "Epoch [159/300], Loss: 0.6215181350708008, Accuracy: 65.00%\n",
            "Epoch [160/300], Loss: 0.6177074909210205, Accuracy: 67.00%\n",
            "Epoch [161/300], Loss: 0.6164759993553162, Accuracy: 64.00%\n",
            "Epoch [162/300], Loss: 0.617374837398529, Accuracy: 63.00%\n",
            "Epoch [163/300], Loss: 0.6143399477005005, Accuracy: 64.00%\n",
            "Epoch [164/300], Loss: 0.6107800006866455, Accuracy: 62.00%\n",
            "Epoch [165/300], Loss: 0.6089060306549072, Accuracy: 62.00%\n",
            "Epoch [166/300], Loss: 0.6087983846664429, Accuracy: 63.00%\n",
            "Epoch [167/300], Loss: 0.6080219149589539, Accuracy: 63.00%\n",
            "Epoch [168/300], Loss: 0.6039637923240662, Accuracy: 62.00%\n",
            "Epoch [169/300], Loss: 0.602480411529541, Accuracy: 63.00%\n",
            "Epoch [170/300], Loss: 0.6030257940292358, Accuracy: 63.00%\n",
            "Epoch [171/300], Loss: 0.6006662845611572, Accuracy: 62.00%\n",
            "Epoch [172/300], Loss: 0.5978431105613708, Accuracy: 62.00%\n",
            "Epoch [173/300], Loss: 0.5957731008529663, Accuracy: 61.00%\n",
            "Epoch [174/300], Loss: 0.5953240394592285, Accuracy: 62.00%\n",
            "Epoch [175/300], Loss: 0.5964033007621765, Accuracy: 63.00%\n",
            "Epoch [176/300], Loss: 0.5948650240898132, Accuracy: 63.00%\n",
            "Epoch [177/300], Loss: 0.5933489799499512, Accuracy: 62.00%\n",
            "Epoch [178/300], Loss: 0.5892531871795654, Accuracy: 63.00%\n",
            "Epoch [179/300], Loss: 0.5888460278511047, Accuracy: 63.00%\n",
            "Epoch [180/300], Loss: 0.5910298228263855, Accuracy: 65.00%\n",
            "Epoch [181/300], Loss: 0.5882448554039001, Accuracy: 63.00%\n",
            "Epoch [182/300], Loss: 0.5855376124382019, Accuracy: 63.00%\n",
            "Epoch [183/300], Loss: 0.5843800902366638, Accuracy: 63.00%\n",
            "Epoch [184/300], Loss: 0.5849359631538391, Accuracy: 62.00%\n",
            "Epoch [185/300], Loss: 0.5856093764305115, Accuracy: 64.00%\n",
            "Epoch [186/300], Loss: 0.5823456048965454, Accuracy: 63.00%\n",
            "Epoch [187/300], Loss: 0.5805582404136658, Accuracy: 63.00%\n",
            "Epoch [188/300], Loss: 0.580752432346344, Accuracy: 64.00%\n",
            "Epoch [189/300], Loss: 0.5802962183952332, Accuracy: 65.00%\n",
            "Epoch [190/300], Loss: 0.579013466835022, Accuracy: 64.00%\n",
            "Epoch [191/300], Loss: 0.5769650936126709, Accuracy: 64.00%\n",
            "Epoch [192/300], Loss: 0.5763247609138489, Accuracy: 64.00%\n",
            "Epoch [193/300], Loss: 0.5765101909637451, Accuracy: 64.00%\n",
            "Epoch [194/300], Loss: 0.5753577947616577, Accuracy: 65.00%\n",
            "Epoch [195/300], Loss: 0.5738279223442078, Accuracy: 64.00%\n",
            "Epoch [196/300], Loss: 0.5723571181297302, Accuracy: 64.00%\n",
            "Epoch [197/300], Loss: 0.5717183947563171, Accuracy: 65.00%\n",
            "Epoch [198/300], Loss: 0.5715767741203308, Accuracy: 65.00%\n",
            "Epoch [199/300], Loss: 0.5708572864532471, Accuracy: 65.00%\n",
            "Epoch [200/300], Loss: 0.5700689554214478, Accuracy: 66.00%\n",
            "Epoch [201/300], Loss: 0.568290650844574, Accuracy: 64.00%\n",
            "Epoch [202/300], Loss: 0.5668166875839233, Accuracy: 65.00%\n",
            "Epoch [203/300], Loss: 0.5657938122749329, Accuracy: 64.00%\n",
            "Epoch [204/300], Loss: 0.5651645660400391, Accuracy: 64.00%\n",
            "Epoch [205/300], Loss: 0.5648741126060486, Accuracy: 67.00%\n",
            "Epoch [206/300], Loss: 0.5644556879997253, Accuracy: 67.00%\n",
            "Epoch [207/300], Loss: 0.5645993947982788, Accuracy: 67.00%\n",
            "Epoch [208/300], Loss: 0.5632245540618896, Accuracy: 66.00%\n",
            "Epoch [209/300], Loss: 0.5621472597122192, Accuracy: 67.00%\n",
            "Epoch [210/300], Loss: 0.5600244998931885, Accuracy: 65.00%\n",
            "Epoch [211/300], Loss: 0.5585349202156067, Accuracy: 64.00%\n",
            "Epoch [212/300], Loss: 0.5577912926673889, Accuracy: 66.00%\n",
            "Epoch [213/300], Loss: 0.5575360655784607, Accuracy: 66.00%\n",
            "Epoch [214/300], Loss: 0.5576761960983276, Accuracy: 67.00%\n",
            "Epoch [215/300], Loss: 0.5570733547210693, Accuracy: 67.00%\n",
            "Epoch [216/300], Loss: 0.5569157600402832, Accuracy: 67.00%\n",
            "Epoch [217/300], Loss: 0.5548949837684631, Accuracy: 67.00%\n",
            "Epoch [218/300], Loss: 0.5531310439109802, Accuracy: 67.00%\n",
            "Epoch [219/300], Loss: 0.5517228841781616, Accuracy: 63.00%\n",
            "Epoch [220/300], Loss: 0.5511637330055237, Accuracy: 65.00%\n",
            "Epoch [221/300], Loss: 0.5511531829833984, Accuracy: 67.00%\n",
            "Epoch [222/300], Loss: 0.5508439540863037, Accuracy: 68.00%\n",
            "Epoch [223/300], Loss: 0.5507274270057678, Accuracy: 67.00%\n",
            "Epoch [224/300], Loss: 0.5491211414337158, Accuracy: 68.00%\n",
            "Epoch [225/300], Loss: 0.5476576685905457, Accuracy: 67.00%\n",
            "Epoch [226/300], Loss: 0.5461214184761047, Accuracy: 65.00%\n",
            "Epoch [227/300], Loss: 0.5451813340187073, Accuracy: 66.00%\n",
            "Epoch [228/300], Loss: 0.5447492599487305, Accuracy: 67.00%\n",
            "Epoch [229/300], Loss: 0.5444260239601135, Accuracy: 67.00%\n",
            "Epoch [230/300], Loss: 0.544198215007782, Accuracy: 67.00%\n",
            "Epoch [231/300], Loss: 0.5432775616645813, Accuracy: 68.00%\n",
            "Epoch [232/300], Loss: 0.5424631834030151, Accuracy: 67.00%\n",
            "Epoch [233/300], Loss: 0.5410515069961548, Accuracy: 67.00%\n",
            "Epoch [234/300], Loss: 0.5398105382919312, Accuracy: 68.00%\n",
            "Epoch [235/300], Loss: 0.5386565327644348, Accuracy: 66.00%\n",
            "Epoch [236/300], Loss: 0.5377317667007446, Accuracy: 67.00%\n",
            "Epoch [237/300], Loss: 0.5369919538497925, Accuracy: 67.00%\n",
            "Epoch [238/300], Loss: 0.5364010334014893, Accuracy: 67.00%\n",
            "Epoch [239/300], Loss: 0.53609299659729, Accuracy: 68.00%\n",
            "Epoch [240/300], Loss: 0.5360199213027954, Accuracy: 70.00%\n",
            "Epoch [241/300], Loss: 0.5372622609138489, Accuracy: 68.00%\n",
            "Epoch [242/300], Loss: 0.5376219153404236, Accuracy: 70.00%\n",
            "Epoch [243/300], Loss: 0.5395891666412354, Accuracy: 68.00%\n",
            "Epoch [244/300], Loss: 0.5344306826591492, Accuracy: 70.00%\n",
            "Epoch [245/300], Loss: 0.5306330323219299, Accuracy: 68.00%\n",
            "Epoch [246/300], Loss: 0.5302004814147949, Accuracy: 69.00%\n",
            "Epoch [247/300], Loss: 0.5317283868789673, Accuracy: 70.00%\n",
            "Epoch [248/300], Loss: 0.532860279083252, Accuracy: 68.00%\n",
            "Epoch [249/300], Loss: 0.528822124004364, Accuracy: 71.00%\n",
            "Epoch [250/300], Loss: 0.5263172388076782, Accuracy: 68.00%\n",
            "Epoch [251/300], Loss: 0.5266292095184326, Accuracy: 69.00%\n",
            "Epoch [252/300], Loss: 0.5272791385650635, Accuracy: 71.00%\n",
            "Epoch [253/300], Loss: 0.5270198583602905, Accuracy: 68.00%\n",
            "Epoch [254/300], Loss: 0.5239076018333435, Accuracy: 71.00%\n",
            "Epoch [255/300], Loss: 0.5224105715751648, Accuracy: 70.00%\n",
            "Epoch [256/300], Loss: 0.5229405760765076, Accuracy: 68.00%\n",
            "Epoch [257/300], Loss: 0.5227490067481995, Accuracy: 71.00%\n",
            "Epoch [258/300], Loss: 0.5216054916381836, Accuracy: 68.00%\n",
            "Epoch [259/300], Loss: 0.5193419456481934, Accuracy: 70.00%\n",
            "Epoch [260/300], Loss: 0.5182477235794067, Accuracy: 70.00%\n",
            "Epoch [261/300], Loss: 0.5182808637619019, Accuracy: 69.00%\n",
            "Epoch [262/300], Loss: 0.5181140899658203, Accuracy: 71.00%\n",
            "Epoch [263/300], Loss: 0.5176495909690857, Accuracy: 68.00%\n",
            "Epoch [264/300], Loss: 0.5157384276390076, Accuracy: 72.00%\n",
            "Epoch [265/300], Loss: 0.5140569806098938, Accuracy: 69.00%\n",
            "Epoch [266/300], Loss: 0.5131371021270752, Accuracy: 70.00%\n",
            "Epoch [267/300], Loss: 0.5128961205482483, Accuracy: 72.00%\n",
            "Epoch [268/300], Loss: 0.5128960609436035, Accuracy: 68.00%\n",
            "Epoch [269/300], Loss: 0.5121470093727112, Accuracy: 71.00%\n",
            "Epoch [270/300], Loss: 0.5115015506744385, Accuracy: 69.00%\n",
            "Epoch [271/300], Loss: 0.5097598433494568, Accuracy: 72.00%\n",
            "Epoch [272/300], Loss: 0.508232831954956, Accuracy: 69.00%\n",
            "Epoch [273/300], Loss: 0.506856381893158, Accuracy: 72.00%\n",
            "Epoch [274/300], Loss: 0.5058121085166931, Accuracy: 71.00%\n",
            "Epoch [275/300], Loss: 0.5050745606422424, Accuracy: 71.00%\n",
            "Epoch [276/300], Loss: 0.5045695304870605, Accuracy: 72.00%\n",
            "Epoch [277/300], Loss: 0.504553496837616, Accuracy: 68.00%\n",
            "Epoch [278/300], Loss: 0.5048478841781616, Accuracy: 73.00%\n",
            "Epoch [279/300], Loss: 0.5078027248382568, Accuracy: 69.00%\n",
            "Epoch [280/300], Loss: 0.5074599385261536, Accuracy: 71.00%\n",
            "Epoch [281/300], Loss: 0.5071433782577515, Accuracy: 70.00%\n",
            "Epoch [282/300], Loss: 0.5002260208129883, Accuracy: 73.00%\n",
            "Epoch [283/300], Loss: 0.4977458119392395, Accuracy: 71.00%\n",
            "Epoch [284/300], Loss: 0.5001415014266968, Accuracy: 69.00%\n",
            "Epoch [285/300], Loss: 0.5014341473579407, Accuracy: 72.00%\n",
            "Epoch [286/300], Loss: 0.5031896829605103, Accuracy: 71.00%\n",
            "Epoch [287/300], Loss: 0.49593842029571533, Accuracy: 74.00%\n",
            "Epoch [288/300], Loss: 0.4934093952178955, Accuracy: 73.00%\n",
            "Epoch [289/300], Loss: 0.4967811107635498, Accuracy: 69.00%\n",
            "Epoch [290/300], Loss: 0.49562567472457886, Accuracy: 71.00%\n",
            "Epoch [291/300], Loss: 0.49220502376556396, Accuracy: 71.00%\n",
            "Epoch [292/300], Loss: 0.48922955989837646, Accuracy: 72.00%\n",
            "Epoch [293/300], Loss: 0.49025726318359375, Accuracy: 74.00%\n",
            "Epoch [294/300], Loss: 0.4918670654296875, Accuracy: 70.00%\n",
            "Epoch [295/300], Loss: 0.48856133222579956, Accuracy: 73.00%\n",
            "Epoch [296/300], Loss: 0.48570677638053894, Accuracy: 70.00%\n",
            "Epoch [297/300], Loss: 0.4843744933605194, Accuracy: 71.00%\n",
            "Epoch [298/300], Loss: 0.4844972491264343, Accuracy: 73.00%\n",
            "Epoch [299/300], Loss: 0.484059602022171, Accuracy: 71.00%\n",
            "Epoch [300/300], Loss: 0.481920063495636, Accuracy: 72.00%\n",
            "Confusion Matrix:\n",
            "[[32 16]\n",
            " [12 40]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Set the random seed for NumPy\n",
        "np.random.seed(42)\n",
        "\n",
        "# Set the random seed for PyTorch\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Define your data\n",
        "X_train_num = np.random.rand(100, 9, 1)\n",
        "y_train = np.random.randint(0, 2, size=(100, 1))\n",
        "\n",
        "# Convert NumPy arrays to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train_num, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "\n",
        "# Define the LSTM model\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Create the LSTM model\n",
        "input_size = 1\n",
        "hidden_size = 64\n",
        "output_size = 1\n",
        "model = LSTMModel(input_size, hidden_size, output_size)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()  # Binary cross-entropy loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 300\n",
        "for epoch in range(num_epochs):\n",
        "    outputs = model(X_train_tensor)\n",
        "    loss = criterion(outputs, y_train_tensor)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    accuracy = calculate_accuracy(torch.sigmoid(outputs), y_train_tensor)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}, Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Calculate and print the confusion matrix\n",
        "y_pred = (torch.sigmoid(outputs) >= 0.5).squeeze().numpy()\n",
        "y_true = y_train.squeeze()\n",
        "confusion = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVPZikKWk0b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc56f3e6-5ac0-417d-d3f6-21e585912015"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualize the confusion matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion, annot=True, fmt=\"d\", cmap=\"Pastel1\", xticklabels=[\"Predicted 0\", \"Predicted 1\"], yticklabels=[\"Actual 0\", \"Actual 1\"])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score ,recall_score\n",
        "\n",
        "# True labels (y_true) and predicted labels (y_pred)\n",
        "y_true = [0]*32 + [1]*12 + [0]*16 + [1]*40\n",
        "y_pred = [0]*32 + [0]*12 + [1]*16 + [1]*40\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(y_true, y_pred)\n",
        "print(\"Precision:\", precision)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "print(f'Recall score: {recall:.2f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wROA10MHoGr",
        "outputId": "f8e5ea6e-4811-4d92-992b-e8d1ca5a3eba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.7142857142857143\n",
            "Recall score: 0.77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFVer20-dY6L"
      },
      "source": [
        "Hybrid GRU+LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrfRG2hAaMY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31a6d86d-de10-41bd-cb02-c1f57b383e1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/320], Loss: 0.6924992203712463, Accuracy: 52.00%\n",
            "Epoch [2/320], Loss: 0.6924186944961548, Accuracy: 52.00%\n",
            "Epoch [3/320], Loss: 0.6923487186431885, Accuracy: 52.00%\n",
            "Epoch [4/320], Loss: 0.6922537088394165, Accuracy: 52.00%\n",
            "Epoch [5/320], Loss: 0.6921778917312622, Accuracy: 52.00%\n",
            "Epoch [6/320], Loss: 0.6921107769012451, Accuracy: 52.00%\n",
            "Epoch [7/320], Loss: 0.6920304298400879, Accuracy: 52.00%\n",
            "Epoch [8/320], Loss: 0.6919405460357666, Accuracy: 52.00%\n",
            "Epoch [9/320], Loss: 0.6918536424636841, Accuracy: 52.00%\n",
            "Epoch [10/320], Loss: 0.6917708516120911, Accuracy: 52.00%\n",
            "Epoch [11/320], Loss: 0.6916812658309937, Accuracy: 52.00%\n",
            "Epoch [12/320], Loss: 0.6915799975395203, Accuracy: 52.00%\n",
            "Epoch [13/320], Loss: 0.6914737224578857, Accuracy: 52.00%\n",
            "Epoch [14/320], Loss: 0.6913669109344482, Accuracy: 52.00%\n",
            "Epoch [15/320], Loss: 0.6912524700164795, Accuracy: 52.00%\n",
            "Epoch [16/320], Loss: 0.69112229347229, Accuracy: 52.00%\n",
            "Epoch [17/320], Loss: 0.6909805536270142, Accuracy: 52.00%\n",
            "Epoch [18/320], Loss: 0.6908318400382996, Accuracy: 52.00%\n",
            "Epoch [19/320], Loss: 0.6906670331954956, Accuracy: 52.00%\n",
            "Epoch [20/320], Loss: 0.690479576587677, Accuracy: 52.00%\n",
            "Epoch [21/320], Loss: 0.690277636051178, Accuracy: 54.00%\n",
            "Epoch [22/320], Loss: 0.6900541186332703, Accuracy: 53.00%\n",
            "Epoch [23/320], Loss: 0.6897979974746704, Accuracy: 53.00%\n",
            "Epoch [24/320], Loss: 0.6895202398300171, Accuracy: 53.00%\n",
            "Epoch [25/320], Loss: 0.6892096996307373, Accuracy: 53.00%\n",
            "Epoch [26/320], Loss: 0.6888716816902161, Accuracy: 56.00%\n",
            "Epoch [27/320], Loss: 0.6885102987289429, Accuracy: 55.00%\n",
            "Epoch [28/320], Loss: 0.6881393194198608, Accuracy: 53.00%\n",
            "Epoch [29/320], Loss: 0.6877796053886414, Accuracy: 57.00%\n",
            "Epoch [30/320], Loss: 0.6874874234199524, Accuracy: 54.00%\n",
            "Epoch [31/320], Loss: 0.6873531341552734, Accuracy: 56.00%\n",
            "Epoch [32/320], Loss: 0.6875237822532654, Accuracy: 51.00%\n",
            "Epoch [33/320], Loss: 0.6874266862869263, Accuracy: 55.00%\n",
            "Epoch [34/320], Loss: 0.6873819828033447, Accuracy: 53.00%\n",
            "Epoch [35/320], Loss: 0.6873258352279663, Accuracy: 51.00%\n",
            "Epoch [36/320], Loss: 0.687102198600769, Accuracy: 51.00%\n",
            "Epoch [37/320], Loss: 0.6869335770606995, Accuracy: 53.00%\n",
            "Epoch [38/320], Loss: 0.6867236495018005, Accuracy: 53.00%\n",
            "Epoch [39/320], Loss: 0.6865167021751404, Accuracy: 52.00%\n",
            "Epoch [40/320], Loss: 0.6864003539085388, Accuracy: 52.00%\n",
            "Epoch [41/320], Loss: 0.6862077116966248, Accuracy: 54.00%\n",
            "Epoch [42/320], Loss: 0.6861173510551453, Accuracy: 58.00%\n",
            "Epoch [43/320], Loss: 0.6859828233718872, Accuracy: 57.00%\n",
            "Epoch [44/320], Loss: 0.6858360171318054, Accuracy: 56.00%\n",
            "Epoch [45/320], Loss: 0.6857264637947083, Accuracy: 53.00%\n",
            "Epoch [46/320], Loss: 0.6855545043945312, Accuracy: 55.00%\n",
            "Epoch [47/320], Loss: 0.6853852272033691, Accuracy: 57.00%\n",
            "Epoch [48/320], Loss: 0.6852165460586548, Accuracy: 57.00%\n",
            "Epoch [49/320], Loss: 0.6849928498268127, Accuracy: 56.00%\n",
            "Epoch [50/320], Loss: 0.6847835779190063, Accuracy: 54.00%\n",
            "Epoch [51/320], Loss: 0.6845501661300659, Accuracy: 53.00%\n",
            "Epoch [52/320], Loss: 0.684291660785675, Accuracy: 56.00%\n",
            "Epoch [53/320], Loss: 0.6840498447418213, Accuracy: 56.00%\n",
            "Epoch [54/320], Loss: 0.6837667226791382, Accuracy: 54.00%\n",
            "Epoch [55/320], Loss: 0.6835036277770996, Accuracy: 52.00%\n",
            "Epoch [56/320], Loss: 0.6832095384597778, Accuracy: 53.00%\n",
            "Epoch [57/320], Loss: 0.6829246282577515, Accuracy: 53.00%\n",
            "Epoch [58/320], Loss: 0.6826037764549255, Accuracy: 53.00%\n",
            "Epoch [59/320], Loss: 0.6822817921638489, Accuracy: 52.00%\n",
            "Epoch [60/320], Loss: 0.6819161176681519, Accuracy: 52.00%\n",
            "Epoch [61/320], Loss: 0.6815482974052429, Accuracy: 55.00%\n",
            "Epoch [62/320], Loss: 0.6811351776123047, Accuracy: 54.00%\n",
            "Epoch [63/320], Loss: 0.680715799331665, Accuracy: 54.00%\n",
            "Epoch [64/320], Loss: 0.6802777051925659, Accuracy: 56.00%\n",
            "Epoch [65/320], Loss: 0.6798142790794373, Accuracy: 55.00%\n",
            "Epoch [66/320], Loss: 0.6793469190597534, Accuracy: 55.00%\n",
            "Epoch [67/320], Loss: 0.6788508892059326, Accuracy: 54.00%\n",
            "Epoch [68/320], Loss: 0.6783289909362793, Accuracy: 54.00%\n",
            "Epoch [69/320], Loss: 0.6777883172035217, Accuracy: 53.00%\n",
            "Epoch [70/320], Loss: 0.6772176623344421, Accuracy: 54.00%\n",
            "Epoch [71/320], Loss: 0.6766122579574585, Accuracy: 54.00%\n",
            "Epoch [72/320], Loss: 0.6759795546531677, Accuracy: 55.00%\n",
            "Epoch [73/320], Loss: 0.6753244996070862, Accuracy: 54.00%\n",
            "Epoch [74/320], Loss: 0.6746978759765625, Accuracy: 54.00%\n",
            "Epoch [75/320], Loss: 0.6743419170379639, Accuracy: 55.00%\n",
            "Epoch [76/320], Loss: 0.6737686395645142, Accuracy: 56.00%\n",
            "Epoch [77/320], Loss: 0.6725262999534607, Accuracy: 52.00%\n",
            "Epoch [78/320], Loss: 0.6718875169754028, Accuracy: 52.00%\n",
            "Epoch [79/320], Loss: 0.6711134314537048, Accuracy: 56.00%\n",
            "Epoch [80/320], Loss: 0.6699267625808716, Accuracy: 57.00%\n",
            "Epoch [81/320], Loss: 0.6692087054252625, Accuracy: 56.00%\n",
            "Epoch [82/320], Loss: 0.6678851246833801, Accuracy: 57.00%\n",
            "Epoch [83/320], Loss: 0.6668655276298523, Accuracy: 57.00%\n",
            "Epoch [84/320], Loss: 0.665804386138916, Accuracy: 59.00%\n",
            "Epoch [85/320], Loss: 0.6642775535583496, Accuracy: 60.00%\n",
            "Epoch [86/320], Loss: 0.6631603837013245, Accuracy: 62.00%\n",
            "Epoch [87/320], Loss: 0.6619431972503662, Accuracy: 63.00%\n",
            "Epoch [88/320], Loss: 0.6601884365081787, Accuracy: 60.00%\n",
            "Epoch [89/320], Loss: 0.6589143872261047, Accuracy: 60.00%\n",
            "Epoch [90/320], Loss: 0.6577388644218445, Accuracy: 63.00%\n",
            "Epoch [91/320], Loss: 0.6558380126953125, Accuracy: 59.00%\n",
            "Epoch [92/320], Loss: 0.6542057991027832, Accuracy: 62.00%\n",
            "Epoch [93/320], Loss: 0.6530442833900452, Accuracy: 64.00%\n",
            "Epoch [94/320], Loss: 0.6522733569145203, Accuracy: 62.00%\n",
            "Epoch [95/320], Loss: 0.652306079864502, Accuracy: 66.00%\n",
            "Epoch [96/320], Loss: 0.6486362218856812, Accuracy: 65.00%\n",
            "Epoch [97/320], Loss: 0.647442638874054, Accuracy: 66.00%\n",
            "Epoch [98/320], Loss: 0.6474026441574097, Accuracy: 65.00%\n",
            "Epoch [99/320], Loss: 0.6430723071098328, Accuracy: 66.00%\n",
            "Epoch [100/320], Loss: 0.642794132232666, Accuracy: 67.00%\n",
            "Epoch [101/320], Loss: 0.6414539217948914, Accuracy: 65.00%\n",
            "Epoch [102/320], Loss: 0.6372166275978088, Accuracy: 67.00%\n",
            "Epoch [103/320], Loss: 0.6381319165229797, Accuracy: 66.00%\n",
            "Epoch [104/320], Loss: 0.6332520246505737, Accuracy: 66.00%\n",
            "Epoch [105/320], Loss: 0.6319707632064819, Accuracy: 61.00%\n",
            "Epoch [106/320], Loss: 0.6292030215263367, Accuracy: 64.00%\n",
            "Epoch [107/320], Loss: 0.6253830790519714, Accuracy: 65.00%\n",
            "Epoch [108/320], Loss: 0.6245154738426208, Accuracy: 66.00%\n",
            "Epoch [109/320], Loss: 0.6196637153625488, Accuracy: 66.00%\n",
            "Epoch [110/320], Loss: 0.6178171038627625, Accuracy: 67.00%\n",
            "Epoch [111/320], Loss: 0.6161131858825684, Accuracy: 68.00%\n",
            "Epoch [112/320], Loss: 0.6114639043807983, Accuracy: 69.00%\n",
            "Epoch [113/320], Loss: 0.6094033718109131, Accuracy: 70.00%\n",
            "Epoch [114/320], Loss: 0.6088181138038635, Accuracy: 63.00%\n",
            "Epoch [115/320], Loss: 0.6054663062095642, Accuracy: 70.00%\n",
            "Epoch [116/320], Loss: 0.6016752123832703, Accuracy: 71.00%\n",
            "Epoch [117/320], Loss: 0.6002823710441589, Accuracy: 69.00%\n",
            "Epoch [118/320], Loss: 0.5992940664291382, Accuracy: 68.00%\n",
            "Epoch [119/320], Loss: 0.5964988470077515, Accuracy: 70.00%\n",
            "Epoch [120/320], Loss: 0.5927011966705322, Accuracy: 71.00%\n",
            "Epoch [121/320], Loss: 0.5908669829368591, Accuracy: 70.00%\n",
            "Epoch [122/320], Loss: 0.5900400280952454, Accuracy: 69.00%\n",
            "Epoch [123/320], Loss: 0.5874693393707275, Accuracy: 70.00%\n",
            "Epoch [124/320], Loss: 0.583917498588562, Accuracy: 70.00%\n",
            "Epoch [125/320], Loss: 0.5812506675720215, Accuracy: 70.00%\n",
            "Epoch [126/320], Loss: 0.579796552658081, Accuracy: 73.00%\n",
            "Epoch [127/320], Loss: 0.5781587362289429, Accuracy: 71.00%\n",
            "Epoch [128/320], Loss: 0.5749273300170898, Accuracy: 72.00%\n",
            "Epoch [129/320], Loss: 0.5714852213859558, Accuracy: 72.00%\n",
            "Epoch [130/320], Loss: 0.5688478350639343, Accuracy: 72.00%\n",
            "Epoch [131/320], Loss: 0.5670132040977478, Accuracy: 73.00%\n",
            "Epoch [132/320], Loss: 0.5655255317687988, Accuracy: 72.00%\n",
            "Epoch [133/320], Loss: 0.5634470582008362, Accuracy: 69.00%\n",
            "Epoch [134/320], Loss: 0.5608639717102051, Accuracy: 72.00%\n",
            "Epoch [135/320], Loss: 0.5570309162139893, Accuracy: 70.00%\n",
            "Epoch [136/320], Loss: 0.5535210371017456, Accuracy: 71.00%\n",
            "Epoch [137/320], Loss: 0.5509036183357239, Accuracy: 71.00%\n",
            "Epoch [138/320], Loss: 0.5490467548370361, Accuracy: 71.00%\n",
            "Epoch [139/320], Loss: 0.5477126836776733, Accuracy: 70.00%\n",
            "Epoch [140/320], Loss: 0.5459337830543518, Accuracy: 69.00%\n",
            "Epoch [141/320], Loss: 0.5440168976783752, Accuracy: 70.00%\n",
            "Epoch [142/320], Loss: 0.5395990014076233, Accuracy: 70.00%\n",
            "Epoch [143/320], Loss: 0.5355729460716248, Accuracy: 71.00%\n",
            "Epoch [144/320], Loss: 0.5328537821769714, Accuracy: 71.00%\n",
            "Epoch [145/320], Loss: 0.5314332842826843, Accuracy: 70.00%\n",
            "Epoch [146/320], Loss: 0.5314781665802002, Accuracy: 71.00%\n",
            "Epoch [147/320], Loss: 0.5300788879394531, Accuracy: 71.00%\n",
            "Epoch [148/320], Loss: 0.5333051085472107, Accuracy: 72.00%\n",
            "Epoch [149/320], Loss: 0.5227667689323425, Accuracy: 73.00%\n",
            "Epoch [150/320], Loss: 0.5171486139297485, Accuracy: 71.00%\n",
            "Epoch [151/320], Loss: 0.5148897767066956, Accuracy: 72.00%\n",
            "Epoch [152/320], Loss: 0.5161463022232056, Accuracy: 75.00%\n",
            "Epoch [153/320], Loss: 0.527803897857666, Accuracy: 72.00%\n",
            "Epoch [154/320], Loss: 0.5151569843292236, Accuracy: 74.00%\n",
            "Epoch [155/320], Loss: 0.5083667039871216, Accuracy: 73.00%\n",
            "Epoch [156/320], Loss: 0.5022374987602234, Accuracy: 73.00%\n",
            "Epoch [157/320], Loss: 0.5015484690666199, Accuracy: 77.00%\n",
            "Epoch [158/320], Loss: 0.5064703226089478, Accuracy: 73.00%\n",
            "Epoch [159/320], Loss: 0.5054954290390015, Accuracy: 75.00%\n",
            "Epoch [160/320], Loss: 0.5060820579528809, Accuracy: 75.00%\n",
            "Epoch [161/320], Loss: 0.49190279841423035, Accuracy: 79.00%\n",
            "Epoch [162/320], Loss: 0.4897080957889557, Accuracy: 79.00%\n",
            "Epoch [163/320], Loss: 0.4975389540195465, Accuracy: 75.00%\n",
            "Epoch [164/320], Loss: 0.49387192726135254, Accuracy: 78.00%\n",
            "Epoch [165/320], Loss: 0.487862765789032, Accuracy: 75.00%\n",
            "Epoch [166/320], Loss: 0.4793698787689209, Accuracy: 79.00%\n",
            "Epoch [167/320], Loss: 0.47912758588790894, Accuracy: 79.00%\n",
            "Epoch [168/320], Loss: 0.48522838950157166, Accuracy: 76.00%\n",
            "Epoch [169/320], Loss: 0.48302406072616577, Accuracy: 77.00%\n",
            "Epoch [170/320], Loss: 0.4784253239631653, Accuracy: 75.00%\n",
            "Epoch [171/320], Loss: 0.4689444601535797, Accuracy: 79.00%\n",
            "Epoch [172/320], Loss: 0.46563124656677246, Accuracy: 81.00%\n",
            "Epoch [173/320], Loss: 0.467899352312088, Accuracy: 76.00%\n",
            "Epoch [174/320], Loss: 0.4719294607639313, Accuracy: 78.00%\n",
            "Epoch [175/320], Loss: 0.4777078926563263, Accuracy: 76.00%\n",
            "Epoch [176/320], Loss: 0.4641720950603485, Accuracy: 79.00%\n",
            "Epoch [177/320], Loss: 0.4543232321739197, Accuracy: 77.00%\n",
            "Epoch [178/320], Loss: 0.45119693875312805, Accuracy: 79.00%\n",
            "Epoch [179/320], Loss: 0.4541783034801483, Accuracy: 80.00%\n",
            "Epoch [180/320], Loss: 0.46205058693885803, Accuracy: 76.00%\n",
            "Epoch [181/320], Loss: 0.45770835876464844, Accuracy: 80.00%\n",
            "Epoch [182/320], Loss: 0.45019227266311646, Accuracy: 78.00%\n",
            "Epoch [183/320], Loss: 0.43891263008117676, Accuracy: 81.00%\n",
            "Epoch [184/320], Loss: 0.43544596433639526, Accuracy: 81.00%\n",
            "Epoch [185/320], Loss: 0.43867170810699463, Accuracy: 81.00%\n",
            "Epoch [186/320], Loss: 0.4428056478500366, Accuracy: 81.00%\n",
            "Epoch [187/320], Loss: 0.4482455849647522, Accuracy: 77.00%\n",
            "Epoch [188/320], Loss: 0.4336404502391815, Accuracy: 81.00%\n",
            "Epoch [189/320], Loss: 0.4228860139846802, Accuracy: 83.00%\n",
            "Epoch [190/320], Loss: 0.41818511486053467, Accuracy: 82.00%\n",
            "Epoch [191/320], Loss: 0.42000412940979004, Accuracy: 81.00%\n",
            "Epoch [192/320], Loss: 0.42763596773147583, Accuracy: 80.00%\n",
            "Epoch [193/320], Loss: 0.4274742901325226, Accuracy: 81.00%\n",
            "Epoch [194/320], Loss: 0.42684680223464966, Accuracy: 81.00%\n",
            "Epoch [195/320], Loss: 0.40950798988342285, Accuracy: 82.00%\n",
            "Epoch [196/320], Loss: 0.4004606604576111, Accuracy: 82.00%\n",
            "Epoch [197/320], Loss: 0.40053433179855347, Accuracy: 83.00%\n",
            "Epoch [198/320], Loss: 0.4048663377761841, Accuracy: 82.00%\n",
            "Epoch [199/320], Loss: 0.41289278864860535, Accuracy: 80.00%\n",
            "Epoch [200/320], Loss: 0.4039444029331207, Accuracy: 83.00%\n",
            "Epoch [201/320], Loss: 0.39485299587249756, Accuracy: 84.00%\n",
            "Epoch [202/320], Loss: 0.3832230865955353, Accuracy: 82.00%\n",
            "Epoch [203/320], Loss: 0.3802095055580139, Accuracy: 82.00%\n",
            "Epoch [204/320], Loss: 0.38409316539764404, Accuracy: 85.00%\n",
            "Epoch [205/320], Loss: 0.386534184217453, Accuracy: 83.00%\n",
            "Epoch [206/320], Loss: 0.3915248215198517, Accuracy: 83.00%\n",
            "Epoch [207/320], Loss: 0.3810623288154602, Accuracy: 83.00%\n",
            "Epoch [208/320], Loss: 0.3714126646518707, Accuracy: 85.00%\n",
            "Epoch [209/320], Loss: 0.3609062433242798, Accuracy: 84.00%\n",
            "Epoch [210/320], Loss: 0.3584488034248352, Accuracy: 85.00%\n",
            "Epoch [211/320], Loss: 0.3621593117713928, Accuracy: 85.00%\n",
            "Epoch [212/320], Loss: 0.3640098571777344, Accuracy: 83.00%\n",
            "Epoch [213/320], Loss: 0.3691883385181427, Accuracy: 83.00%\n",
            "Epoch [214/320], Loss: 0.3615622818470001, Accuracy: 83.00%\n",
            "Epoch [215/320], Loss: 0.3545248508453369, Accuracy: 86.00%\n",
            "Epoch [216/320], Loss: 0.3408913314342499, Accuracy: 86.00%\n",
            "Epoch [217/320], Loss: 0.3350980281829834, Accuracy: 88.00%\n",
            "Epoch [218/320], Loss: 0.33714306354522705, Accuracy: 86.00%\n",
            "Epoch [219/320], Loss: 0.3389509916305542, Accuracy: 85.00%\n",
            "Epoch [220/320], Loss: 0.3426143229007721, Accuracy: 86.00%\n",
            "Epoch [221/320], Loss: 0.33653077483177185, Accuracy: 85.00%\n",
            "Epoch [222/320], Loss: 0.331371545791626, Accuracy: 86.00%\n",
            "Epoch [223/320], Loss: 0.31970280408859253, Accuracy: 88.00%\n",
            "Epoch [224/320], Loss: 0.31305834650993347, Accuracy: 87.00%\n",
            "Epoch [225/320], Loss: 0.3124851584434509, Accuracy: 88.00%\n",
            "Epoch [226/320], Loss: 0.3132246732711792, Accuracy: 87.00%\n",
            "Epoch [227/320], Loss: 0.3147163689136505, Accuracy: 85.00%\n",
            "Epoch [228/320], Loss: 0.31004783511161804, Accuracy: 87.00%\n",
            "Epoch [229/320], Loss: 0.3062186539173126, Accuracy: 87.00%\n",
            "Epoch [230/320], Loss: 0.2979693114757538, Accuracy: 88.00%\n",
            "Epoch [231/320], Loss: 0.2921390235424042, Accuracy: 88.00%\n",
            "Epoch [232/320], Loss: 0.28967180848121643, Accuracy: 87.00%\n",
            "Epoch [233/320], Loss: 0.2890426218509674, Accuracy: 88.00%\n",
            "Epoch [234/320], Loss: 0.28878146409988403, Accuracy: 87.00%\n",
            "Epoch [235/320], Loss: 0.2849756181240082, Accuracy: 88.00%\n",
            "Epoch [236/320], Loss: 0.28121528029441833, Accuracy: 87.00%\n",
            "Epoch [237/320], Loss: 0.275544136762619, Accuracy: 88.00%\n",
            "Epoch [238/320], Loss: 0.27146053314208984, Accuracy: 86.00%\n",
            "Epoch [239/320], Loss: 0.2692951560020447, Accuracy: 87.00%\n",
            "Epoch [240/320], Loss: 0.2676369547843933, Accuracy: 88.00%\n",
            "Epoch [241/320], Loss: 0.2658264636993408, Accuracy: 87.00%\n",
            "Epoch [242/320], Loss: 0.26203712821006775, Accuracy: 88.00%\n",
            "Epoch [243/320], Loss: 0.25813528895378113, Accuracy: 87.00%\n",
            "Epoch [244/320], Loss: 0.25438442826271057, Accuracy: 87.00%\n",
            "Epoch [245/320], Loss: 0.2518142759799957, Accuracy: 88.00%\n",
            "Epoch [246/320], Loss: 0.2498781532049179, Accuracy: 88.00%\n",
            "Epoch [247/320], Loss: 0.24725881218910217, Accuracy: 89.00%\n",
            "Epoch [248/320], Loss: 0.2442256361246109, Accuracy: 88.00%\n",
            "Epoch [249/320], Loss: 0.24067218601703644, Accuracy: 88.00%\n",
            "Epoch [250/320], Loss: 0.2376301884651184, Accuracy: 88.00%\n",
            "Epoch [251/320], Loss: 0.2352341264486313, Accuracy: 88.00%\n",
            "Epoch [252/320], Loss: 0.23284344375133514, Accuracy: 88.00%\n",
            "Epoch [253/320], Loss: 0.23013630509376526, Accuracy: 88.00%\n",
            "Epoch [254/320], Loss: 0.22699636220932007, Accuracy: 89.00%\n",
            "Epoch [255/320], Loss: 0.22407355904579163, Accuracy: 90.00%\n",
            "Epoch [256/320], Loss: 0.2215633988380432, Accuracy: 91.00%\n",
            "Epoch [257/320], Loss: 0.21914686262607574, Accuracy: 92.00%\n",
            "Epoch [258/320], Loss: 0.21653719246387482, Accuracy: 91.00%\n",
            "Epoch [259/320], Loss: 0.21369241178035736, Accuracy: 92.00%\n",
            "Epoch [260/320], Loss: 0.2109796553850174, Accuracy: 92.00%\n",
            "Epoch [261/320], Loss: 0.20851972699165344, Accuracy: 92.00%\n",
            "Epoch [262/320], Loss: 0.20611612498760223, Accuracy: 92.00%\n",
            "Epoch [263/320], Loss: 0.20359133183956146, Accuracy: 93.00%\n",
            "Epoch [264/320], Loss: 0.20095616579055786, Accuracy: 92.00%\n",
            "Epoch [265/320], Loss: 0.19842727482318878, Accuracy: 92.00%\n",
            "Epoch [266/320], Loss: 0.19605915248394012, Accuracy: 93.00%\n",
            "Epoch [267/320], Loss: 0.1937127262353897, Accuracy: 92.00%\n",
            "Epoch [268/320], Loss: 0.1912917196750641, Accuracy: 93.00%\n",
            "Epoch [269/320], Loss: 0.18883424997329712, Accuracy: 93.00%\n",
            "Epoch [270/320], Loss: 0.1864580363035202, Accuracy: 93.00%\n",
            "Epoch [271/320], Loss: 0.18417949974536896, Accuracy: 93.00%\n",
            "Epoch [272/320], Loss: 0.18191799521446228, Accuracy: 93.00%\n",
            "Epoch [273/320], Loss: 0.1796189695596695, Accuracy: 94.00%\n",
            "Epoch [274/320], Loss: 0.17731042206287384, Accuracy: 94.00%\n",
            "Epoch [275/320], Loss: 0.17506277561187744, Accuracy: 94.00%\n",
            "Epoch [276/320], Loss: 0.17288008332252502, Accuracy: 94.00%\n",
            "Epoch [277/320], Loss: 0.17070996761322021, Accuracy: 94.00%\n",
            "Epoch [278/320], Loss: 0.16852422058582306, Accuracy: 94.00%\n",
            "Epoch [279/320], Loss: 0.16634264588356018, Accuracy: 94.00%\n",
            "Epoch [280/320], Loss: 0.16420328617095947, Accuracy: 94.00%\n",
            "Epoch [281/320], Loss: 0.16210445761680603, Accuracy: 94.00%\n",
            "Epoch [282/320], Loss: 0.16001121699810028, Accuracy: 94.00%\n",
            "Epoch [283/320], Loss: 0.15790818631649017, Accuracy: 94.00%\n",
            "Epoch [284/320], Loss: 0.15581145882606506, Accuracy: 94.00%\n",
            "Epoch [285/320], Loss: 0.1537400484085083, Accuracy: 94.00%\n",
            "Epoch [286/320], Loss: 0.15168315172195435, Accuracy: 94.00%\n",
            "Epoch [287/320], Loss: 0.1496162861585617, Accuracy: 94.00%\n",
            "Epoch [288/320], Loss: 0.14753586053848267, Accuracy: 94.00%\n",
            "Epoch [289/320], Loss: 0.14545415341854095, Accuracy: 94.00%\n",
            "Epoch [290/320], Loss: 0.14337676763534546, Accuracy: 94.00%\n",
            "Epoch [291/320], Loss: 0.1412939429283142, Accuracy: 94.00%\n",
            "Epoch [292/320], Loss: 0.13919858634471893, Accuracy: 95.00%\n",
            "Epoch [293/320], Loss: 0.13710147142410278, Accuracy: 95.00%\n",
            "Epoch [294/320], Loss: 0.13502229750156403, Accuracy: 95.00%\n",
            "Epoch [295/320], Loss: 0.13297198712825775, Accuracy: 95.00%\n",
            "Epoch [296/320], Loss: 0.13095255196094513, Accuracy: 95.00%\n",
            "Epoch [297/320], Loss: 0.12896549701690674, Accuracy: 95.00%\n",
            "Epoch [298/320], Loss: 0.12701177597045898, Accuracy: 95.00%\n",
            "Epoch [299/320], Loss: 0.12509113550186157, Accuracy: 95.00%\n",
            "Epoch [300/320], Loss: 0.12319851666688919, Accuracy: 95.00%\n",
            "Epoch [301/320], Loss: 0.12132707238197327, Accuracy: 96.00%\n",
            "Epoch [302/320], Loss: 0.1194726973772049, Accuracy: 96.00%\n",
            "Epoch [303/320], Loss: 0.11763619631528854, Accuracy: 96.00%\n",
            "Epoch [304/320], Loss: 0.11582054942846298, Accuracy: 96.00%\n",
            "Epoch [305/320], Loss: 0.11402725428342819, Accuracy: 97.00%\n",
            "Epoch [306/320], Loss: 0.11225467920303345, Accuracy: 97.00%\n",
            "Epoch [307/320], Loss: 0.11049920320510864, Accuracy: 98.00%\n",
            "Epoch [308/320], Loss: 0.1087585911154747, Accuracy: 97.00%\n",
            "Epoch [309/320], Loss: 0.10703317821025848, Accuracy: 98.00%\n",
            "Epoch [310/320], Loss: 0.10532451421022415, Accuracy: 98.00%\n",
            "Epoch [311/320], Loss: 0.10363306105136871, Accuracy: 98.00%\n",
            "Epoch [312/320], Loss: 0.10195659846067429, Accuracy: 98.00%\n",
            "Epoch [313/320], Loss: 0.10029163211584091, Accuracy: 98.00%\n",
            "Epoch [314/320], Loss: 0.0986342504620552, Accuracy: 98.00%\n",
            "Epoch [315/320], Loss: 0.09698304533958435, Accuracy: 98.00%\n",
            "Epoch [316/320], Loss: 0.09533792734146118, Accuracy: 98.00%\n",
            "Epoch [317/320], Loss: 0.09370109438896179, Accuracy: 98.00%\n",
            "Epoch [318/320], Loss: 0.09207456558942795, Accuracy: 98.00%\n",
            "Epoch [319/320], Loss: 0.09046030044555664, Accuracy: 98.00%\n",
            "Epoch [320/320], Loss: 0.08885914087295532, Accuracy: 98.00%\n",
            "Confusion Matrix:\n",
            "[[47  1]\n",
            " [ 1 51]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Set the random seed for NumPy and PyTorch\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Define your data\n",
        "X_train_num = np.random.rand(100, 9, 1)\n",
        "y_train = np.random.randint(0, 2, size=(100, 1))\n",
        "\n",
        "# Convert NumPy arrays to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train_num, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "\n",
        "# Define the hybrid model with LSTM and GRU layers\n",
        "class HybridModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(HybridModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_lstm, _ = self.lstm(x)\n",
        "        out_gru, _ = self.gru(out_lstm)\n",
        "        out = self.fc(out_gru[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Create the hybrid model\n",
        "input_size = 1\n",
        "hidden_size = 64\n",
        "output_size = 1\n",
        "model = HybridModel(input_size, hidden_size, output_size)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()  # Binary cross-entropy loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the hybrid model\n",
        "num_epochs = 320\n",
        "for epoch in range(num_epochs):\n",
        "    outputs = model(X_train_tensor)\n",
        "    loss = criterion(outputs, y_train_tensor)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    accuracy = calculate_accuracy(torch.sigmoid(outputs), y_train_tensor)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}, Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "\n",
        "# Calculate and print the confusion matrix\n",
        "y_pred = (torch.sigmoid(outputs) >= 0.5).squeeze().numpy()\n",
        "y_true = y_train.squeeze()\n",
        "confusion = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUhpDee2JBwV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d0c7fbe-4ca1-4877-dc32-5a1a1a72ef2e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualize the confusion matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion, annot=True, fmt=\"d\", cmap=\"Pastel1\", xticklabels=[\"Predicted 0\", \"Predicted 1\"], yticklabels=[\"Actual 0\", \"Actual 1\"])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "# True labels\n",
        "y_true = np.array([0] * 48 + [1] * 52)\n",
        "\n",
        "# Predicted labels\n",
        "y_pred = np.array([0] * 47 + [1] + [0] + [1] * 51)\n",
        "\n",
        "# Calculate precision\n",
        "recall = recall_score(y_true, y_pred)\n",
        "print(f'Recall score: {recall:.2f}')\n",
        "precision = precision_score(y_true, y_pred)\n",
        "print(\"Precision:\", precision)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fvu-rcdeHCl0",
        "outputId": "1178f0a0-8166-4ab4-ae7a-657f5f8e28a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall score: 0.98\n",
            "Precision: 0.9807692307692307\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}